{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3db99a7b",
   "metadata": {},
   "source": [
    "Importación y configuración de MLflow:\n",
    "Se cargan todas la librerias y las herramientas para la creación de los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5145c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/mlflow/tracking/_tracking_service/utils.py:140: FutureWarning: Filesystem tracking backend (e.g., './mlruns') is deprecated. Please switch to a database backend (e.g., 'sqlite:///mlflow.db'). For feedback, see: https://github.com/mlflow/mlflow/issues/18534\n",
      "  return FileStore(store_uri, store_uri)\n",
      "2025/12/01 13:13:20 INFO mlflow.tracking.fluent: Experiment with name 'airbnb_regresion_nn' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.16.2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "\n",
    "print(\"TensorFlow:\", tf.__version__)\n",
    "\n",
    "# Configuración de MLflow (local, sin tracking_uri raro)\n",
    "mlflow.set_experiment(\"airbnb_regresion_nn\")\n",
    "\n",
    "# Activo autolog para Keras (registra automáticamente métricas, parámetros y modelo)\n",
    "mlflow.keras.autolog()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e94f9b5",
   "metadata": {},
   "source": [
    "Carga del data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "961b7314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>name</th>\n",
       "      <th>host_id</th>\n",
       "      <th>host_name</th>\n",
       "      <th>host_since</th>\n",
       "      <th>host_is_superhost</th>\n",
       "      <th>host_listings_count</th>\n",
       "      <th>host_total_listings_count</th>\n",
       "      <th>host_verifications</th>\n",
       "      <th>...</th>\n",
       "      <th>has_free_street_parking</th>\n",
       "      <th>has_private_entrance</th>\n",
       "      <th>has_essentials</th>\n",
       "      <th>has_heating</th>\n",
       "      <th>has_wifi</th>\n",
       "      <th>has_pets_allowed</th>\n",
       "      <th>has_hot_water</th>\n",
       "      <th>has_self_check_in</th>\n",
       "      <th>has_freezer</th>\n",
       "      <th>has_exercise_equipment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18744501</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>\"Artist´s Creative Residence\" 100m² im Zentrum</td>\n",
       "      <td>129635321</td>\n",
       "      <td>Sylvia</td>\n",
       "      <td>2017-05-09</td>\n",
       "      <td>f</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['email', 'phone']</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23356842</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>\"Bohemian Residency\" (Central &amp; Quiet) * * * * *</td>\n",
       "      <td>150173398</td>\n",
       "      <td>Vincent</td>\n",
       "      <td>2017-09-11</td>\n",
       "      <td>t</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>['email', 'phone']</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>819658084391291386</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>\"Feel at Home\" Flat at the Lerchenauer See</td>\n",
       "      <td>29225873</td>\n",
       "      <td>Skandar</td>\n",
       "      <td>2015-03-12</td>\n",
       "      <td>f</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['email', 'phone']</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34677963</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>\"Little Star\"  Schlafoase im Zentrum</td>\n",
       "      <td>28482431</td>\n",
       "      <td>Adriana</td>\n",
       "      <td>2015-02-28</td>\n",
       "      <td>f</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['email', 'phone']</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34431776</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>\"Moonlight\" Schlafoase mitten im Szenenviertel</td>\n",
       "      <td>28482431</td>\n",
       "      <td>Adriana</td>\n",
       "      <td>2015-02-28</td>\n",
       "      <td>f</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['email', 'phone']</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id       source  \\\n",
       "0            18744501  city scrape   \n",
       "1            23356842  city scrape   \n",
       "2  819658084391291386  city scrape   \n",
       "3            34677963  city scrape   \n",
       "4            34431776  city scrape   \n",
       "\n",
       "                                               name    host_id host_name  \\\n",
       "0    \"Artist´s Creative Residence\" 100m² im Zentrum  129635321    Sylvia   \n",
       "1  \"Bohemian Residency\" (Central & Quiet) * * * * *  150173398   Vincent   \n",
       "2        \"Feel at Home\" Flat at the Lerchenauer See   29225873   Skandar   \n",
       "3              \"Little Star\"  Schlafoase im Zentrum   28482431   Adriana   \n",
       "4    \"Moonlight\" Schlafoase mitten im Szenenviertel   28482431   Adriana   \n",
       "\n",
       "   host_since host_is_superhost  host_listings_count  \\\n",
       "0  2017-05-09                 f                  1.0   \n",
       "1  2017-09-11                 t                  2.0   \n",
       "2  2015-03-12                 f                  1.0   \n",
       "3  2015-02-28                 f                  5.0   \n",
       "4  2015-02-28                 f                  5.0   \n",
       "\n",
       "   host_total_listings_count  host_verifications  ... has_free_street_parking  \\\n",
       "0                        1.0  ['email', 'phone']  ...                       1   \n",
       "1                        3.0  ['email', 'phone']  ...                       1   \n",
       "2                        1.0  ['email', 'phone']  ...                       0   \n",
       "3                        5.0  ['email', 'phone']  ...                       0   \n",
       "4                        5.0  ['email', 'phone']  ...                       0   \n",
       "\n",
       "  has_private_entrance has_essentials has_heating  has_wifi  has_pets_allowed  \\\n",
       "0                    1              1           1         1                 0   \n",
       "1                    1              1           1         1                 0   \n",
       "2                    0              1           1         1                 1   \n",
       "3                    1              1           1         1                 0   \n",
       "4                    1              1           1         1                 0   \n",
       "\n",
       "  has_hot_water has_self_check_in  has_freezer  has_exercise_equipment  \n",
       "0             1                 0            0                       0  \n",
       "1             1                 1            0                       0  \n",
       "2             1                 0            0                       1  \n",
       "3             1                 1            0                       0  \n",
       "4             1                 1            0                       0  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(\"/Users/S340/Documents/Octavo/Analítica de datos /airbnb-proyecto2-20252/airbnb_limpio.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd36aaa",
   "metadata": {},
   "source": [
    "Limpieza de la variable predictoria. La variable 'price' viene como texto \"string\" con símbolos. Se limpia y se transforma en numérico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e55884cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    221.0\n",
       " 1    797.0\n",
       " 2    106.0\n",
       " 3    258.0\n",
       " 4    249.0\n",
       " Name: price, dtype: float64,\n",
       " dtype('float64'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"price\"] = (\n",
    "    df[\"price\"]\n",
    "    .str.replace(\"$\", \"\", regex=False)\n",
    "    .str.replace(\",\", \"\", regex=False)\n",
    "    .astype(float)\n",
    ")\n",
    "\n",
    "df[\"price\"].head(), df[\"price\"].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09989c1",
   "metadata": {},
   "source": [
    "Hacemos una tranformación logarítmica del precio ya que este tiene una distribución muy asimétrica. Esto se hace para estabilizar la varianza y mejorar los modelos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbdc218f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5562.000000\n",
       "mean        5.243958\n",
       "std         0.744214\n",
       "min         2.772589\n",
       "25%         4.727388\n",
       "50%         5.198497\n",
       "75%         5.707110\n",
       "max         9.332912\n",
       "Name: price_log, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"price_log\"] = np.log1p(df[\"price\"])\n",
    "df[\"price_log\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3141e2",
   "metadata": {},
   "source": [
    "Selección de la variables.\n",
    "Seleccionamos las variables numéricas y transformadas anteriormente por el equipo del TEC. Se excluyen columnas textuales y redundantes. Estas variables se usarán para entrenar las redes neuronales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "961a45ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5562, 59), (5562,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = [\n",
    "    'latitude','longitude','accommodates','bathrooms','bedrooms','beds',\n",
    "    'minimum_nights','maximum_nights','minimum_minimum_nights','maximum_minimum_nights',\n",
    "    'minimum_maximum_nights','maximum_maximum_nights','minimum_nights_avg_ntm',\n",
    "    'maximum_nights_avg_ntm','availability_30','availability_60','availability_90',\n",
    "    'availability_365','number_of_reviews','number_of_reviews_ltm','number_of_reviews_l30d',\n",
    "    'availability_eoy','number_of_reviews_ly','estimated_occupancy_l365d',\n",
    "    'estimated_revenue_l365d',\n",
    "    'calculated_host_listings_count','calculated_host_listings_count_entire_homes',\n",
    "    'calculated_host_listings_count_private_rooms','calculated_host_listings_count_shared_rooms',\n",
    "    'is_Entire_home_apt','is_Hotel_room','is_Private_room','is_Shared_room',\n",
    "    'accommodates_1_to_4','accommodates_5_to_10','accommodates_greater_than_10',\n",
    "    'bathrooms_menor_o_igual_1_5','bathrooms_mas_de_1_5','is_shared_bathroom',\n",
    "    'is_private_bathroom','bedrooms_le_2','bedrooms_3_to_5','bedrooms_gt_6',\n",
    "    'beds_0_to_3','beds_4_to_8','beds_9_to_13','beds_gt_13',\n",
    "    'is_instant_bookable_binary','has_free_street_parking','has_private_entrance',\n",
    "    'has_essentials','has_heating','has_wifi','has_pets_allowed','has_hot_water',\n",
    "    'has_self_check_in','has_freezer','has_exercise_equipment','has_binary'\n",
    "]\n",
    "\n",
    "X = df[feature_cols].copy()\n",
    "y = df[\"price_log\"].copy()\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614c1535",
   "metadata": {},
   "source": [
    "División Train/Test\n",
    "Se dividen los datos en en entrenamiento y prueba y se escalan los features con StandarScaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f750efcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4449, 59), (1113, 59))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled.shape, X_test_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed84fe8",
   "metadata": {},
   "source": [
    "Función auxiliar para evaluar modelos: \n",
    "Defino una función auxiliar para evaluar cada red neuronal en la escala real del precio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e49b3d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_real_scale(model, X_test_scaled, y_test, prefix=\"\"):\n",
    "    # Predicciones en escala log\n",
    "    y_pred_log = model.predict(X_test_scaled).ravel()\n",
    "    \n",
    "    # Pasar a escala real\n",
    "    y_pred = np.expm1(y_pred_log)\n",
    "    y_true = np.expm1(y_test.values)\n",
    "    \n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    if prefix:\n",
    "        print(f\"{prefix} - MAE: {mae:.2f}, RMSE: {rmse:.2f}, R2: {r2:.4f}\")\n",
    "    else:\n",
    "        print(f\"MAE: {mae:.2f}, RMSE: {rmse:.2f}, R2: {r2:.4f}\")\n",
    "    \n",
    "    return mae, rmse, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b1c024",
   "metadata": {},
   "source": [
    "Primer modelo de regresion: RN1 (Red Neuronal 1)\n",
    "Este es el primer modelo de referencia. Uso una arquitectura sencilla (64 → 32 → 16) con activación ReLU en las capas ocultas y salida lineal para regresión.  \n",
    "Sirve como punto de comparación para evaluar si las arquitecturas posteriores realmente mejoran el desempeño.  \n",
    "El modelo se registra en MLflow con sus parámetros y métricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66cd7c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/core/dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-12-01 13:13:20.921746: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2025-12-01 13:13:20.921930: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2025-12-01 13:13:20.921938: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2025-12-01 13:13:20.922455: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-12-01 13:13:20.922465: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2025/12/01 13:13:21 WARNING mlflow.keras.autologging: Failed to log dataset information to MLflow. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 13:13:21.500216: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - loss: 21.2727 - mae: 4.3275 - val_loss: 18.1766 - val_mae: 3.4715\n",
      "Epoch 2/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 12.5761 - mae: 2.7992 - val_loss: 33.4024 - val_mae: 2.5741\n",
      "Epoch 3/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 31.0130 - mae: 3.4021 - val_loss: 10.5358 - val_mae: 2.2349\n",
      "Epoch 4/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.9795 - mae: 1.8026 - val_loss: 6.9098 - val_mae: 1.0973\n",
      "Epoch 5/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 29.9604 - mae: 2.7901 - val_loss: 15.4527 - val_mae: 2.9607\n",
      "Epoch 6/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 16.0347 - mae: 2.1879 - val_loss: 3.1117 - val_mae: 1.0414\n",
      "Epoch 7/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3.8886 - mae: 1.1691 - val_loss: 28.7984 - val_mae: 3.9125\n",
      "Epoch 8/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 97.8299 - mae: 5.3572 - val_loss: 4.4539 - val_mae: 1.5351\n",
      "Epoch 9/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3.0559 - mae: 1.0740 - val_loss: 3.5943 - val_mae: 1.3861\n",
      "Epoch 10/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.0388 - mae: 0.9237 - val_loss: 3.1159 - val_mae: 0.8068\n",
      "Epoch 11/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.6123 - mae: 0.7944 - val_loss: 1.4432 - val_mae: 0.7536\n",
      "Epoch 12/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.5282 - mae: 0.7845 - val_loss: 1.4374 - val_mae: 0.8218\n",
      "Epoch 13/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3.2035 - mae: 1.1155 - val_loss: 1.1147 - val_mae: 0.5801\n",
      "Epoch 14/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.0540 - mae: 0.6540 - val_loss: 41.1049 - val_mae: 3.9536\n",
      "Epoch 15/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.7502 - mae: 1.3352 - val_loss: 0.8890 - val_mae: 0.5879\n",
      "Epoch 16/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 9.6608 - mae: 1.7060 - val_loss: 1.7752 - val_mae: 0.7355\n",
      "Epoch 17/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 14.7203 - mae: 1.8710 - val_loss: 70.5896 - val_mae: 5.3611\n",
      "Epoch 18/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6.6949 - mae: 1.5308 - val_loss: 2.7161 - val_mae: 0.8448\n",
      "Epoch 19/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 47.1852 - mae: 2.5261 - val_loss: 1157.8756 - val_mae: 22.0882\n",
      "Epoch 20/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 227.0787 - mae: 7.5619 - val_loss: 10.0734 - val_mae: 1.4029\n",
      "Epoch 21/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 3.6637 - mae: 1.1277 - val_loss: 15.8454 - val_mae: 2.0979\n",
      "Epoch 22/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 7.0188 - mae: 1.5178 - val_loss: 1.5510 - val_mae: 0.6932\n",
      "Epoch 23/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.0327 - mae: 1.2174 - val_loss: 1.6400 - val_mae: 0.5966\n",
      "Epoch 24/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.9134 - mae: 0.8591 - val_loss: 3.4868 - val_mae: 1.3942\n",
      "Epoch 25/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.4091 - mae: 0.7420 - val_loss: 0.9545 - val_mae: 0.5459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/01 13:13:50 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/01 13:13:57 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/12/01 13:13:57 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN1 - MAE: 143.58, RMSE: 365.63, R2: 0.0172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/12/01 13:14:02 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def build_nn1(n_features: int):\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(64, activation=\"relu\", input_shape=(n_features,)),\n",
    "        layers.Dense(32, activation=\"relu\"),\n",
    "        layers.Dense(16, activation=\"relu\"),\n",
    "        layers.Dense(1)  # salida lineal\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        loss=\"mse\",\n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "mae_nn1 = rmse_nn1 = r2_nn1 = None\n",
    "\n",
    "with mlflow.start_run(run_name=\"NN1_baseline\"):\n",
    "    mlflow.log_param(\"model_type\", \"NN1_baseline\")\n",
    "    mlflow.log_param(\"layers\", \"64 -> 1\")\n",
    "    mlflow.log_param(\"activation_hidden\", \"ReLU\")\n",
    "    mlflow.log_param(\"learning_rate\", 1e-3)\n",
    "    mlflow.log_param(\"batch_size\", 32)\n",
    "    mlflow.log_param(\"epochs_max\", 80)\n",
    "    mlflow.log_param(\"validation_split\", 0.2)\n",
    "    \n",
    "    nn1 = build_nn1(X_train_scaled.shape[1])\n",
    "    \n",
    "    history1 = nn1.fit(\n",
    "        X_train_scaled, y_train,\n",
    "        validation_split=0.2,\n",
    "        epochs=80,\n",
    "        batch_size=32,\n",
    "        verbose=1,\n",
    "        callbacks=[\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                patience=10, restore_best_weights=True\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    mae_nn1, rmse_nn1, r2_nn1 = evaluate_on_real_scale(nn1, X_test_scaled, y_test, prefix=\"NN1\")\n",
    "    \n",
    "    # Logueo métricas en escala real\n",
    "    mlflow.log_metric(\"MAE_real\", mae_nn1)\n",
    "    mlflow.log_metric(\"RMSE_real\", rmse_nn1)\n",
    "    mlflow.log_metric(\"R2_real\", r2_nn1)\n",
    "    \n",
    "    # Guardo el modelo como artefacto explícito (además del autolog)\n",
    "    mlflow.keras.log_model(nn1, artifact_path=\"nn1_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f4b2ae",
   "metadata": {},
   "source": [
    "Segundo modelo de regresión: (RN2)\n",
    "Segundo modelo con dos capas ocultas y un dropout. Se busca aumentar la capacidad y controlar el sobreajuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb3d74b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/01 13:14:02 WARNING mlflow.keras.autologging: Failed to log dataset information to MLflow. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 22.2927 - mae: 4.0227 - val_loss: 11.3872 - val_mae: 2.9637\n",
      "Epoch 2/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 7.0354 - mae: 2.0055 - val_loss: 4.1192 - val_mae: 1.0750\n",
      "Epoch 3/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 3.1872 - mae: 1.2406 - val_loss: 1.0468 - val_mae: 0.6610\n",
      "Epoch 4/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.9858 - mae: 0.9824 - val_loss: 0.7455 - val_mae: 0.5125\n",
      "Epoch 5/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.4649 - mae: 0.8545 - val_loss: 0.4391 - val_mae: 0.4621\n",
      "Epoch 6/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.2089 - mae: 0.7901 - val_loss: 0.4009 - val_mae: 0.4652\n",
      "Epoch 7/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 2.8226 - mae: 1.0899 - val_loss: 0.7407 - val_mae: 0.5552\n",
      "Epoch 8/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.1713 - mae: 0.7533 - val_loss: 1.2472 - val_mae: 0.6794\n",
      "Epoch 9/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.2235 - mae: 0.7504 - val_loss: 1.0011 - val_mae: 0.4986\n",
      "Epoch 10/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.9333 - mae: 0.6784 - val_loss: 0.6320 - val_mae: 0.5351\n",
      "Epoch 11/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.2194 - mae: 0.7606 - val_loss: 0.7394 - val_mae: 0.6507\n",
      "Epoch 12/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.6817 - mae: 0.8432 - val_loss: 0.3931 - val_mae: 0.4662\n",
      "Epoch 13/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.7852 - mae: 0.8901 - val_loss: 1.2099 - val_mae: 0.5841\n",
      "Epoch 14/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.3481 - mae: 0.8173 - val_loss: 0.5992 - val_mae: 0.5957\n",
      "Epoch 15/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.5960 - mae: 0.8200 - val_loss: 1.8812 - val_mae: 0.9433\n",
      "Epoch 16/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.2017 - mae: 0.7669 - val_loss: 0.7406 - val_mae: 0.4854\n",
      "Epoch 17/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.2389 - mae: 0.7375 - val_loss: 4.6422 - val_mae: 0.8036\n",
      "Epoch 18/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 3.6673 - mae: 1.2693 - val_loss: 0.7970 - val_mae: 0.5897\n",
      "Epoch 19/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 2.0962 - mae: 0.9270 - val_loss: 0.4548 - val_mae: 0.5105\n",
      "Epoch 20/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.7360 - mae: 0.6244 - val_loss: 0.3524 - val_mae: 0.4499\n",
      "Epoch 21/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.6450 - mae: 0.5804 - val_loss: 0.4832 - val_mae: 0.4477\n",
      "Epoch 22/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.9662 - mae: 0.6844 - val_loss: 0.4253 - val_mae: 0.5028\n",
      "Epoch 23/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.8852 - mae: 0.6768 - val_loss: 0.3980 - val_mae: 0.4687\n",
      "Epoch 24/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 2.5322 - mae: 0.9805 - val_loss: 0.6874 - val_mae: 0.6124\n",
      "Epoch 25/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 2.6534 - mae: 1.0389 - val_loss: 1.6111 - val_mae: 0.9628\n",
      "Epoch 26/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.7683 - mae: 0.6156 - val_loss: 0.6133 - val_mae: 0.4944\n",
      "Epoch 27/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.5173 - mae: 0.7983 - val_loss: 1.4034 - val_mae: 0.8885\n",
      "Epoch 28/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.7731 - mae: 0.6208 - val_loss: 0.4192 - val_mae: 0.4949\n",
      "Epoch 29/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.1266 - mae: 0.7301 - val_loss: 1.4862 - val_mae: 0.7421\n",
      "Epoch 30/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.7910 - mae: 0.6521 - val_loss: 0.8487 - val_mae: 0.6857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/01 13:14:31 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/01 13:14:36 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/12/01 13:14:36 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN2 - MAE: 113.28, RMSE: 343.43, R2: 0.1329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/12/01 13:14:41 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def build_nn2(n_features: int):\n",
    "    inp = keras.Input(shape=(n_features,))\n",
    "    x = layers.Dense(128, activation=\"relu\")(inp)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(64, activation=\"relu\")(x)\n",
    "    out = layers.Dense(1)(x)\n",
    "    \n",
    "    model = keras.Model(inputs=inp, outputs=out)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        loss=\"mse\",\n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "mae_nn2 = rmse_nn2 = r2_nn2 = None\n",
    "\n",
    "with mlflow.start_run(run_name=\"NN2_deeper_dropout\"):\n",
    "    mlflow.log_param(\"model_type\", \"NN2_deeper_dropout\")\n",
    "    mlflow.log_param(\"layers\", \"128 -> 64 -> 1\")\n",
    "    mlflow.log_param(\"activation_hidden\", \"ReLU\")\n",
    "    mlflow.log_param(\"dropout_first\", 0.3)\n",
    "    mlflow.log_param(\"learning_rate\", 1e-3)\n",
    "    mlflow.log_param(\"batch_size\", 32)\n",
    "    mlflow.log_param(\"epochs_max\", 80)\n",
    "    mlflow.log_param(\"validation_split\", 0.2)\n",
    "    \n",
    "    nn2 = build_nn2(X_train_scaled.shape[1])\n",
    "    \n",
    "    history2 = nn2.fit(\n",
    "        X_train_scaled, y_train,\n",
    "        validation_split=0.2,\n",
    "        epochs=80,\n",
    "        batch_size=32,\n",
    "        verbose=1,\n",
    "        callbacks=[\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                patience=10, restore_best_weights=True\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    mae_nn2, rmse_nn2, r2_nn2 = evaluate_on_real_scale(nn2, X_test_scaled, y_test, prefix=\"NN2\")\n",
    "    \n",
    "    mlflow.log_metric(\"MAE_real\", mae_nn2)\n",
    "    mlflow.log_metric(\"RMSE_real\", rmse_nn2)\n",
    "    mlflow.log_metric(\"R2_real\", r2_nn2)\n",
    "    \n",
    "    mlflow.keras.log_model(nn2, artifact_path=\"nn2_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b64052f",
   "metadata": {},
   "source": [
    "Tercer modelo de redes neuronales: (RN3)\n",
    "Se hace un tercer con modelo con mayor profundidad, batch de normalización, regularización y activación ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bee260fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/01 13:14:42 WARNING mlflow.keras.autologging: Failed to log dataset information to MLflow. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 24.1820 - mae: 4.6843 - val_loss: 16.6717 - val_mae: 4.0255 - learning_rate: 5.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 12.5020 - mae: 3.2250 - val_loss: 5.3232 - val_mae: 2.2217 - learning_rate: 5.0000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 5.5034 - mae: 1.8851 - val_loss: 1.2093 - val_mae: 0.9477 - learning_rate: 5.0000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.0452 - mae: 1.5191 - val_loss: 0.8211 - val_mae: 0.7467 - learning_rate: 5.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 3.2509 - mae: 1.3741 - val_loss: 0.8970 - val_mae: 0.7731 - learning_rate: 5.0000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 2.8819 - mae: 1.2941 - val_loss: 1.3527 - val_mae: 0.9390 - learning_rate: 5.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 2.5098 - mae: 1.2125 - val_loss: 0.9208 - val_mae: 0.7559 - learning_rate: 5.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 2.3224 - mae: 1.1575 - val_loss: 0.8371 - val_mae: 0.7206 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 1.8547 - mae: 1.0441 - val_loss: 0.5967 - val_mae: 0.6024 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 1.5435 - mae: 0.9521 - val_loss: 0.4850 - val_mae: 0.5407 - learning_rate: 5.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 1.1813 - mae: 0.8259 - val_loss: 0.5071 - val_mae: 0.5490 - learning_rate: 5.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.8520 - mae: 0.7010 - val_loss: 0.3979 - val_mae: 0.4754 - learning_rate: 5.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.6200 - mae: 0.6143 - val_loss: 0.3250 - val_mae: 0.4380 - learning_rate: 5.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.5291 - mae: 0.5621 - val_loss: 0.3525 - val_mae: 0.4715 - learning_rate: 5.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.4396 - mae: 0.5142 - val_loss: 0.3316 - val_mae: 0.4343 - learning_rate: 5.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.3743 - mae: 0.4786 - val_loss: 0.2905 - val_mae: 0.4176 - learning_rate: 5.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.4001 - mae: 0.4891 - val_loss: 0.4204 - val_mae: 0.5235 - learning_rate: 5.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.3878 - mae: 0.4808 - val_loss: 0.3853 - val_mae: 0.4577 - learning_rate: 5.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.4110 - mae: 0.4952 - val_loss: 0.3175 - val_mae: 0.4477 - learning_rate: 5.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.3691 - mae: 0.4704 - val_loss: 0.2816 - val_mae: 0.4108 - learning_rate: 5.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.4167 - mae: 0.5023 - val_loss: 0.4889 - val_mae: 0.5218 - learning_rate: 5.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.5737 - mae: 0.5846 - val_loss: 0.2796 - val_mae: 0.4033 - learning_rate: 5.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.4133 - mae: 0.4920 - val_loss: 0.3179 - val_mae: 0.4318 - learning_rate: 5.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.3953 - mae: 0.4858 - val_loss: 0.3441 - val_mae: 0.4584 - learning_rate: 5.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.3572 - mae: 0.4644 - val_loss: 0.3051 - val_mae: 0.4191 - learning_rate: 5.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.3334 - mae: 0.4502 - val_loss: 0.3077 - val_mae: 0.4356 - learning_rate: 5.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.4208 - mae: 0.5024 - val_loss: 0.2999 - val_mae: 0.4254 - learning_rate: 5.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.3429 - mae: 0.4549 - val_loss: 0.3757 - val_mae: 0.4661 - learning_rate: 2.5000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.3249 - mae: 0.4442 - val_loss: 0.2974 - val_mae: 0.4134 - learning_rate: 2.5000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.3189 - mae: 0.4337 - val_loss: 0.2845 - val_mae: 0.4095 - learning_rate: 2.5000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.3235 - mae: 0.4432 - val_loss: 0.3172 - val_mae: 0.4227 - learning_rate: 2.5000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.3178 - mae: 0.4343 - val_loss: 0.3329 - val_mae: 0.4457 - learning_rate: 2.5000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.3038 - mae: 0.4271 - val_loss: 0.3620 - val_mae: 0.4530 - learning_rate: 1.2500e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.3001 - mae: 0.4235 - val_loss: 0.3010 - val_mae: 0.4232 - learning_rate: 1.2500e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/01 13:15:43 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/01 13:15:49 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/12/01 13:15:49 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN3 - MAE: 100.09, RMSE: 322.98, R2: 0.2331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/12/01 13:15:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def build_nn3(n_features: int):\n",
    "    inp = keras.Input(shape=(n_features,))\n",
    "    \n",
    "    x = layers.Dense(256, activation=\"relu\")(inp)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    \n",
    "    x = layers.Dense(128, activation=\"relu\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    x = layers.Dense(64, activation=\"relu\")(x)\n",
    "    \n",
    "    out = layers.Dense(1)(x)\n",
    "    \n",
    "    model = keras.Model(inputs=inp, outputs=out)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=5e-4),\n",
    "        loss=\"mse\",\n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "mae_nn3 = rmse_nn3 = r2_nn3 = None\n",
    "\n",
    "with mlflow.start_run(run_name=\"NN3_deep_bn_dropout\"):\n",
    "    mlflow.log_param(\"model_type\", \"NN3_deep_bn_dropout\")\n",
    "    mlflow.log_param(\"layers\", \"256 -> 128 -> 64 -> 1\")\n",
    "    mlflow.log_param(\"activation_hidden\", \"ReLU\")\n",
    "    mlflow.log_param(\"dropout\", \"0.4, 0.3\")\n",
    "    mlflow.log_param(\"batchnorm\", True)\n",
    "    mlflow.log_param(\"learning_rate\", 5e-4)\n",
    "    mlflow.log_param(\"batch_size\", 32)\n",
    "    mlflow.log_param(\"epochs_max\", 100)\n",
    "    mlflow.log_param(\"validation_split\", 0.2)\n",
    "    \n",
    "    nn3 = build_nn3(X_train_scaled.shape[1])\n",
    "    \n",
    "    history3 = nn3.fit(\n",
    "        X_train_scaled, y_train,\n",
    "        validation_split=0.2,\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        verbose=1,\n",
    "        callbacks=[\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                patience=12, restore_best_weights=True\n",
    "            ),\n",
    "            keras.callbacks.ReduceLROnPlateau(\n",
    "                patience=5, factor=0.5\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    mae_nn3, rmse_nn3, r2_nn3 = evaluate_on_real_scale(nn3, X_test_scaled, y_test, prefix=\"NN3\")\n",
    "    \n",
    "    mlflow.log_metric(\"MAE_real\", mae_nn3)\n",
    "    mlflow.log_metric(\"RMSE_real\", rmse_nn3)\n",
    "    mlflow.log_metric(\"R2_real\", r2_nn3)\n",
    "    \n",
    "    mlflow.keras.log_model(nn3, artifact_path=\"nn3_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c30251",
   "metadata": {},
   "source": [
    "Comparación de modelos neuronales\n",
    "Comparo los resultados de las 3 redes neuronales "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d3e19ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NN1_baseline</td>\n",
       "      <td>143.581453</td>\n",
       "      <td>365.632837</td>\n",
       "      <td>0.017195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NN2_deeper_dropout</td>\n",
       "      <td>113.276728</td>\n",
       "      <td>343.430486</td>\n",
       "      <td>0.132929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NN3_deep_bn_dropout</td>\n",
       "      <td>100.087950</td>\n",
       "      <td>322.982270</td>\n",
       "      <td>0.233108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model         MAE        RMSE        R2\n",
       "0         NN1_baseline  143.581453  365.632837  0.017195\n",
       "1   NN2_deeper_dropout  113.276728  343.430486  0.132929\n",
       "2  NN3_deep_bn_dropout  100.087950  322.982270  0.233108"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_nn = pd.DataFrame({\n",
    "    \"Model\": [\"NN1_baseline\", \"NN2_deeper_dropout\", \"NN3_deep_bn_dropout\"],\n",
    "    \"MAE\": [mae_nn1, mae_nn2, mae_nn3],\n",
    "    \"RMSE\": [rmse_nn1, rmse_nn2, rmse_nn3],\n",
    "    \"R2\": [r2_nn1, r2_nn2, r2_nn3]\n",
    "})\n",
    "\n",
    "results_nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cff3080",
   "metadata": {},
   "source": [
    "Selección del mejor modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe826f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model    NN3_deep_bn_dropout\n",
       "MAE                100.08795\n",
       "RMSE               322.98227\n",
       "R2                  0.233108\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_row = results_nn.iloc[results_nn[\"MAE\"].idxmin()]\n",
    "best_row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a24230",
   "metadata": {},
   "source": [
    "Ampliación en la búsqueda de hiperparámetros:\n",
    "En este modelo cambio dos hiperparámetros clave frente a los anteriores:\n",
    "- Uso un batch size más pequeño (16), lo que introduce más ruido estocástico.\n",
    "- Aumento el learning rate a 0.01.\n",
    "La arquitectura es intermedia (128 → 64 → 32) con activación ReLU. El objetivo es ver si una tasa de aprendizaje más agresiva mejora o empeora el desempeño."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18f4571e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/01 13:15:55 WARNING mlflow.keras.autologging: Failed to log dataset information to MLflow. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 26.7012 - mae: 4.7684 - val_loss: 24.2697 - val_mae: 4.3940\n",
      "Epoch 2/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 18.4492 - mae: 3.8263 - val_loss: 15.1675 - val_mae: 3.4352\n",
      "Epoch 3/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.8708 - mae: 2.8605 - val_loss: 7.5568 - val_mae: 2.4847\n",
      "Epoch 4/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 5.6365 - mae: 2.0173 - val_loss: 4.5665 - val_mae: 1.6887\n",
      "Epoch 5/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 3.1223 - mae: 1.3396 - val_loss: 3.8223 - val_mae: 1.5450\n",
      "Epoch 6/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.0756 - mae: 1.5466 - val_loss: 6.4186 - val_mae: 1.8563\n",
      "Epoch 7/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.0032 - mae: 1.5434 - val_loss: 1.4729 - val_mae: 0.9203\n",
      "Epoch 8/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.7398 - mae: 0.6173 - val_loss: 1.3587 - val_mae: 0.8314\n",
      "Epoch 9/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.4998 - mae: 0.5204 - val_loss: 0.3383 - val_mae: 0.4334\n",
      "Epoch 10/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.4509 - mae: 0.5054 - val_loss: 0.3235 - val_mae: 0.4249\n",
      "Epoch 11/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.3501 - mae: 0.4496 - val_loss: 0.5252 - val_mae: 0.5447\n",
      "Epoch 12/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5441 - mae: 0.5358 - val_loss: 0.4363 - val_mae: 0.5062\n",
      "Epoch 13/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.7030 - mae: 0.6038 - val_loss: 1.9018 - val_mae: 1.0359\n",
      "Epoch 14/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.7129 - mae: 0.5968 - val_loss: 0.3323 - val_mae: 0.4230\n",
      "Epoch 15/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.4353 - mae: 0.4912 - val_loss: 0.3366 - val_mae: 0.4217\n",
      "Epoch 16/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5600 - mae: 0.5386 - val_loss: 0.7325 - val_mae: 0.6326\n",
      "Epoch 17/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.1656 - mae: 1.2620 - val_loss: 13.8519 - val_mae: 2.7516\n",
      "Epoch 18/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.9903 - mae: 0.9940 - val_loss: 0.4589 - val_mae: 0.5170\n",
      "Epoch 19/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.3606 - mae: 0.4525 - val_loss: 0.3672 - val_mae: 0.4570\n",
      "Epoch 20/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.3985 - mae: 0.4628 - val_loss: 0.3637 - val_mae: 0.4559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/01 13:16:07 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/01 13:16:13 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/12/01 13:16:13 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN4 - MAE: 163.95, RMSE: 1172.44, R2: -9.1055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/12/01 13:16:17 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def build_nn4(n_features: int):\n",
    "    inp = keras.Input(shape=(n_features,))\n",
    "    x = layers.Dense(128, activation=\"relu\")(inp)\n",
    "    x = layers.Dense(64, activation=\"relu\")(x)\n",
    "    x = layers.Dense(32, activation=\"relu\")(x)\n",
    "    out = layers.Dense(1)(x)\n",
    "\n",
    "    model = keras.Model(inputs=inp, outputs=out)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=5e-4),\n",
    "        loss=\"mse\",\n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "mae_nn4 = rmse_nn4 = r2_nn4 = None\n",
    "\n",
    "with mlflow.start_run(run_name=\"NN4_low_lr_bs64\"):\n",
    "    mlflow.log_param(\"model_type\", \"NN4_low_lr_bs64\")\n",
    "    mlflow.log_param(\"layers\", \"128 -> 64 -> 32 -> 1\")\n",
    "    mlflow.log_param(\"learning_rate\", 5e-4)\n",
    "    mlflow.log_param(\"batch_size\", 64)\n",
    "    mlflow.log_param(\"activation_hidden\", \"ReLU\")\n",
    "\n",
    "    nn4 = build_nn4(X_train_scaled.shape[1])\n",
    "\n",
    "    history4 = nn4.fit(\n",
    "        X_train_scaled, y_train,\n",
    "        validation_split=0.2,\n",
    "        epochs=80,\n",
    "        batch_size=64,\n",
    "        verbose=1,\n",
    "        callbacks=[\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                patience=10,\n",
    "                restore_best_weights=True\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    mae_nn4, rmse_nn4, r2_nn4 = evaluate_on_real_scale(nn4, X_test_scaled, y_test, prefix=\"NN4\")\n",
    "\n",
    "    mlflow.log_metric(\"MAE_real\", mae_nn4)\n",
    "    mlflow.log_metric(\"RMSE_real\", rmse_nn4)\n",
    "    mlflow.log_metric(\"R2_real\", r2_nn4)\n",
    "\n",
    "    mlflow.keras.log_model(nn4, artifact_path=\"nn4_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1172f5",
   "metadata": {},
   "source": [
    "### 13. Modelo NN5 (arquitectura 256–128–64 + regularización L2 + dropout suave)\n",
    "En NN5 pruebo una arquitectura más grande que NN4, agregando:\n",
    "- Regularización L2 (1e-4) para controlar sobreajuste.\n",
    "- Dropout suave (20%).\n",
    "- Learning rate moderado (0.0008).\n",
    "- Adam como optimizador, capas ReLU.\n",
    "\n",
    "El objetivo es evaluar si una red más ancha pero con regularización mejora la precisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc58c49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/01 13:16:19 WARNING mlflow.keras.autologging: Failed to log dataset information to MLflow. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 19.6851 - mae: 3.8777 - val_loss: 14.7703 - val_mae: 3.1327\n",
      "Epoch 2/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 19.4446 - mae: 3.0186 - val_loss: 3.7744 - val_mae: 1.3287\n",
      "Epoch 3/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 98.8901 - mae: 5.6334 - val_loss: 2.5455 - val_mae: 1.0304\n",
      "Epoch 4/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 21.2697 - mae: 2.6303 - val_loss: 65.1935 - val_mae: 6.1662\n",
      "Epoch 5/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 48.8840 - mae: 4.3906 - val_loss: 19.4720 - val_mae: 3.3596\n",
      "Epoch 6/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 71.2242 - mae: 4.9000 - val_loss: 42.9895 - val_mae: 4.9868\n",
      "Epoch 7/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 29.5948 - mae: 3.5280 - val_loss: 1.2285 - val_mae: 0.7636\n",
      "Epoch 8/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 53.1476 - mae: 4.5599 - val_loss: 205.3013 - val_mae: 11.1382\n",
      "Epoch 9/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 116.8530 - mae: 6.9888 - val_loss: 70.7261 - val_mae: 6.5186\n",
      "Epoch 10/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 396.3993 - mae: 11.3084 - val_loss: 300.9374 - val_mae: 13.5338\n",
      "Epoch 11/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 216.1802 - mae: 7.1592 - val_loss: 12.7765 - val_mae: 2.6444\n",
      "Epoch 12/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 32.8942 - mae: 3.4662 - val_loss: 79.7043 - val_mae: 6.9220\n",
      "Epoch 13/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 22.8162 - mae: 3.0463 - val_loss: 31.0249 - val_mae: 4.1989\n",
      "Epoch 14/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 71.8073 - mae: 5.1901 - val_loss: 248.8757 - val_mae: 12.2437\n",
      "Epoch 15/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 96.2147 - mae: 6.3575 - val_loss: 3.4133 - val_mae: 1.3268\n",
      "Epoch 16/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1503.8865 - mae: 22.3348 - val_loss: 631.7500 - val_mae: 19.4554\n",
      "Epoch 17/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 108.5147 - mae: 6.6017 - val_loss: 29.1997 - val_mae: 3.9401\n",
      "Epoch 18/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 80.4161 - mae: 5.1115 - val_loss: 23.3441 - val_mae: 3.4858\n",
      "Epoch 19/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 32.8585 - mae: 3.6001 - val_loss: 57.0006 - val_mae: 5.7907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/01 13:16:42 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/01 13:16:47 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/12/01 13:16:47 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN5 - MAE: 180.16, RMSE: 718.12, R2: -2.7911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/12/01 13:16:52 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "\n",
    "def build_nn5(n_features: int):\n",
    "    l2_reg = regularizers.l2(1e-4)\n",
    "\n",
    "    inp = keras.Input(shape=(n_features,))\n",
    "    x = layers.Dense(256, activation=\"relu\", kernel_regularizer=l2_reg)(inp)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Dense(128, activation=\"relu\", kernel_regularizer=l2_reg)(x)\n",
    "    x = layers.Dense(64, activation=\"relu\", kernel_regularizer=l2_reg)(x)\n",
    "    out = layers.Dense(1)(x)\n",
    "\n",
    "    model = keras.Model(inputs=inp, outputs=out)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=8e-4),\n",
    "        loss=\"mse\",\n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "mae_nn5 = rmse_nn5 = r2_nn5 = None\n",
    "\n",
    "with mlflow.start_run(run_name=\"NN5_l2_dropout_arch256\"):\n",
    "    mlflow.log_param(\"model_type\", \"NN5_l2_dropout_arch256\")\n",
    "    mlflow.log_param(\"layers\", \"256 -> 128 -> 64 -> 1\")\n",
    "    mlflow.log_param(\"learning_rate\", 8e-4)\n",
    "    mlflow.log_param(\"dropout\", 0.2)\n",
    "    mlflow.log_param(\"l2\", 1e-4)\n",
    "    mlflow.log_param(\"activation_hidden\", \"ReLU\")\n",
    "\n",
    "    nn5 = build_nn5(X_train_scaled.shape[1])\n",
    "\n",
    "    history5 = nn5.fit(\n",
    "        X_train_scaled, y_train,\n",
    "        validation_split=0.2,\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        verbose=1,\n",
    "        callbacks=[\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                patience=12,\n",
    "                restore_best_weights=True\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    mae_nn5, rmse_nn5, r2_nn5 = evaluate_on_real_scale(nn5, X_test_scaled, y_test, prefix=\"NN5\")\n",
    "\n",
    "    mlflow.log_metric(\"MAE_real\", mae_nn5)\n",
    "    mlflow.log_metric(\"RMSE_real\", rmse_nn5)\n",
    "    mlflow.log_metric(\"R2_real\", r2_nn5)\n",
    "\n",
    "    mlflow.keras.log_model(nn5, artifact_path=\"nn5_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e79ba31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/01 13:16:52 WARNING mlflow.keras.autologging: Failed to log dataset information to MLflow. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 27.0296 - mae: 4.6256 - val_loss: 17.7216 - val_mae: 3.9829 - learning_rate: 3.0000e-04\n",
      "Epoch 2/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 28.1952 - mae: 4.2024 - val_loss: 20.0545 - val_mae: 3.6387 - learning_rate: 3.0000e-04\n",
      "Epoch 3/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 142.5268 - mae: 8.0186 - val_loss: 63.8619 - val_mae: 6.2858 - learning_rate: 3.0000e-04\n",
      "Epoch 4/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 249.7858 - mae: 10.7887 - val_loss: 45.6508 - val_mae: 5.3642 - learning_rate: 3.0000e-04\n",
      "Epoch 5/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 643.2095 - mae: 16.2020 - val_loss: 5221.7583 - val_mae: 58.2423 - learning_rate: 3.0000e-04\n",
      "Epoch 6/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1078.4880 - mae: 20.5682 - val_loss: 66.2473 - val_mae: 6.5250 - learning_rate: 3.0000e-04\n",
      "Epoch 7/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 187.6675 - mae: 9.2631 - val_loss: 26.6706 - val_mae: 4.2643 - learning_rate: 3.0000e-04\n",
      "Epoch 8/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 963.9302 - mae: 19.4766 - val_loss: 3912.4041 - val_mae: 50.0868 - learning_rate: 3.0000e-04\n",
      "Epoch 9/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 512.4567 - mae: 14.1363 - val_loss: 450.6352 - val_mae: 16.8798 - learning_rate: 1.5000e-04\n",
      "Epoch 10/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 606.6347 - mae: 15.5095 - val_loss: 36.8489 - val_mae: 4.8875 - learning_rate: 1.5000e-04\n",
      "Epoch 11/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 65.6273 - mae: 5.7562 - val_loss: 95.2125 - val_mae: 7.6368 - learning_rate: 1.5000e-04\n",
      "Epoch 12/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 138.8254 - mae: 6.8348 - val_loss: 121.8528 - val_mae: 8.6480 - learning_rate: 1.5000e-04\n",
      "Epoch 13/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 4316.3311 - mae: 36.2203 - val_loss: 1595.8025 - val_mae: 31.9970 - learning_rate: 1.5000e-04\n",
      "Epoch 14/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 746.2161 - mae: 16.1008 - val_loss: 17.7302 - val_mae: 3.4162 - learning_rate: 1.5000e-04\n",
      "Epoch 15/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 67.6878 - mae: 5.7932 - val_loss: 11.4371 - val_mae: 3.2107 - learning_rate: 1.5000e-04\n",
      "Epoch 16/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 69.4803 - mae: 5.8761 - val_loss: 35.7618 - val_mae: 4.6460 - learning_rate: 1.5000e-04\n",
      "Epoch 17/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 98.9327 - mae: 6.6661 - val_loss: 19.0208 - val_mae: 3.4643 - learning_rate: 1.5000e-04\n",
      "Epoch 18/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 141.2338 - mae: 7.6227 - val_loss: 208.7605 - val_mae: 11.3470 - learning_rate: 1.5000e-04\n",
      "Epoch 19/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1572.8464 - mae: 24.1762 - val_loss: 462.4861 - val_mae: 16.9470 - learning_rate: 1.5000e-04\n",
      "Epoch 20/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 329.2369 - mae: 10.7087 - val_loss: 9.9392 - val_mae: 3.0145 - learning_rate: 1.5000e-04\n",
      "Epoch 21/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 173.0483 - mae: 8.1228 - val_loss: 2662.8960 - val_mae: 40.9230 - learning_rate: 1.5000e-04\n",
      "Epoch 22/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 2049.2666 - mae: 28.4188 - val_loss: 1490.4537 - val_mae: 30.7580 - learning_rate: 1.5000e-04\n",
      "Epoch 23/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 2520.2388 - mae: 29.9129 - val_loss: 74.7469 - val_mae: 6.9253 - learning_rate: 1.5000e-04\n",
      "Epoch 24/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 3745.4399 - mae: 37.2883 - val_loss: 174.8289 - val_mae: 10.5803 - learning_rate: 1.5000e-04\n",
      "Epoch 25/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 964.2526 - mae: 18.6319 - val_loss: 1639.4402 - val_mae: 32.1893 - learning_rate: 1.5000e-04\n",
      "Epoch 26/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1604.3353 - mae: 23.7149 - val_loss: 798.7350 - val_mae: 22.5003 - learning_rate: 1.5000e-04\n",
      "Epoch 27/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 389.4285 - mae: 11.7633 - val_loss: 15.9832 - val_mae: 3.1159 - learning_rate: 1.5000e-04\n",
      "Epoch 28/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 58.9926 - mae: 5.2379 - val_loss: 10.0231 - val_mae: 2.8279 - learning_rate: 7.5000e-05\n",
      "Epoch 29/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 21.5049 - mae: 3.5603 - val_loss: 9.6593 - val_mae: 2.7989 - learning_rate: 7.5000e-05\n",
      "Epoch 30/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 18.6328 - mae: 3.3181 - val_loss: 9.7881 - val_mae: 2.7967 - learning_rate: 7.5000e-05\n",
      "Epoch 31/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 16.0035 - mae: 3.2282 - val_loss: 8.4402 - val_mae: 2.6743 - learning_rate: 7.5000e-05\n",
      "Epoch 32/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 11.6137 - mae: 2.8847 - val_loss: 7.7189 - val_mae: 2.6710 - learning_rate: 7.5000e-05\n",
      "Epoch 33/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 17.1947 - mae: 3.2808 - val_loss: 41.4226 - val_mae: 5.1485 - learning_rate: 7.5000e-05\n",
      "Epoch 34/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 16.1989 - mae: 3.2024 - val_loss: 14.8132 - val_mae: 2.9999 - learning_rate: 7.5000e-05\n",
      "Epoch 35/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 887.2198 - mae: 15.0977 - val_loss: 65.0614 - val_mae: 6.2317 - learning_rate: 7.5000e-05\n",
      "Epoch 36/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 85.5028 - mae: 5.9689 - val_loss: 13.0307 - val_mae: 2.8345 - learning_rate: 7.5000e-05\n",
      "Epoch 37/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 56.8055 - mae: 5.2316 - val_loss: 47.3754 - val_mae: 5.5028 - learning_rate: 7.5000e-05\n",
      "Epoch 38/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 358.4212 - mae: 11.9717 - val_loss: 7.3734 - val_mae: 2.5075 - learning_rate: 7.5000e-05\n",
      "Epoch 39/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 549.3292 - mae: 14.3019 - val_loss: 9.4162 - val_mae: 2.6591 - learning_rate: 7.5000e-05\n",
      "Epoch 40/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 186.4496 - mae: 8.8398 - val_loss: 106.0711 - val_mae: 8.0155 - learning_rate: 7.5000e-05\n",
      "Epoch 41/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1403.9590 - mae: 19.1175 - val_loss: 447.3712 - val_mae: 16.5998 - learning_rate: 7.5000e-05\n",
      "Epoch 42/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 4566.2969 - mae: 42.7718 - val_loss: 1644.5360 - val_mae: 32.1555 - learning_rate: 7.5000e-05\n",
      "Epoch 43/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 843.6280 - mae: 17.6662 - val_loss: 280.5268 - val_mae: 13.3331 - learning_rate: 7.5000e-05\n",
      "Epoch 44/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 126.8635 - mae: 7.0810 - val_loss: 13.1478 - val_mae: 2.7985 - learning_rate: 7.5000e-05\n",
      "Epoch 45/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 23.3527 - mae: 3.4743 - val_loss: 11.8986 - val_mae: 2.8567 - learning_rate: 7.5000e-05\n",
      "Epoch 46/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 9.3738 - mae: 2.5860 - val_loss: 6.1756 - val_mae: 2.3827 - learning_rate: 3.7500e-05\n",
      "Epoch 47/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 8.4087 - mae: 2.5080 - val_loss: 6.6085 - val_mae: 2.3971 - learning_rate: 3.7500e-05\n",
      "Epoch 48/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 8.7377 - mae: 2.5177 - val_loss: 14.0557 - val_mae: 3.0536 - learning_rate: 3.7500e-05\n",
      "Epoch 49/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 8.4865 - mae: 2.5111 - val_loss: 6.5887 - val_mae: 2.3338 - learning_rate: 3.7500e-05\n",
      "Epoch 50/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 10.5817 - mae: 2.6304 - val_loss: 9.6272 - val_mae: 2.6230 - learning_rate: 3.7500e-05\n",
      "Epoch 51/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 9.8258 - mae: 2.5904 - val_loss: 12.3631 - val_mae: 2.7138 - learning_rate: 3.7500e-05\n",
      "Epoch 52/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 13.6205 - mae: 2.8884 - val_loss: 8.8099 - val_mae: 2.5355 - learning_rate: 3.7500e-05\n",
      "Epoch 53/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 10.9302 - mae: 2.6720 - val_loss: 29.7756 - val_mae: 4.3598 - learning_rate: 3.7500e-05\n",
      "Epoch 54/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 9.9013 - mae: 2.5522 - val_loss: 6.9534 - val_mae: 2.2809 - learning_rate: 1.8750e-05\n",
      "Epoch 55/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 8.0161 - mae: 2.4160 - val_loss: 6.0809 - val_mae: 2.2784 - learning_rate: 1.8750e-05\n",
      "Epoch 56/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 8.8188 - mae: 2.5077 - val_loss: 8.0227 - val_mae: 2.4466 - learning_rate: 1.8750e-05\n",
      "Epoch 57/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 8.2077 - mae: 2.4370 - val_loss: 7.2484 - val_mae: 2.3711 - learning_rate: 1.8750e-05\n",
      "Epoch 58/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 8.7661 - mae: 2.4463 - val_loss: 6.0346 - val_mae: 2.2556 - learning_rate: 1.8750e-05\n",
      "Epoch 59/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 6.5413 - mae: 2.2675 - val_loss: 7.1253 - val_mae: 2.3526 - learning_rate: 1.8750e-05\n",
      "Epoch 60/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 6.8978 - mae: 2.2918 - val_loss: 5.6996 - val_mae: 2.2483 - learning_rate: 1.8750e-05\n",
      "Epoch 61/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 8.4457 - mae: 2.4342 - val_loss: 11.3017 - val_mae: 2.7655 - learning_rate: 1.8750e-05\n",
      "Epoch 62/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 8.5360 - mae: 2.4380 - val_loss: 17.7242 - val_mae: 3.3775 - learning_rate: 1.8750e-05\n",
      "Epoch 63/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 10.6868 - mae: 2.6372 - val_loss: 6.0335 - val_mae: 2.2132 - learning_rate: 1.8750e-05\n",
      "Epoch 64/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 13.7916 - mae: 2.8328 - val_loss: 14.0304 - val_mae: 2.8625 - learning_rate: 1.8750e-05\n",
      "Epoch 65/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 281ms/step - loss: 18.8184 - mae: 3.1706 - val_loss: 17.0644 - val_mae: 3.3146 - learning_rate: 1.8750e-05\n",
      "Epoch 66/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 18.8737 - mae: 3.1606 - val_loss: 11.7464 - val_mae: 2.6306 - learning_rate: 1.8750e-05\n",
      "Epoch 67/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 10.3591 - mae: 2.5928 - val_loss: 11.9226 - val_mae: 2.6468 - learning_rate: 1.8750e-05\n",
      "Epoch 68/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 8.1828 - mae: 2.3826 - val_loss: 6.9980 - val_mae: 2.1912 - learning_rate: 9.3750e-06\n",
      "Epoch 69/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.1095 - mae: 2.3516 - val_loss: 7.8603 - val_mae: 2.3904 - learning_rate: 9.3750e-06\n",
      "Epoch 70/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 6.5557 - mae: 2.2491 - val_loss: 11.8494 - val_mae: 2.8048 - learning_rate: 9.3750e-06\n",
      "Epoch 71/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 9.7826 - mae: 2.5288 - val_loss: 7.9465 - val_mae: 2.3947 - learning_rate: 9.3750e-06\n",
      "Epoch 72/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 7.7242 - mae: 2.3342 - val_loss: 6.5141 - val_mae: 2.1552 - learning_rate: 9.3750e-06\n",
      "Epoch 73/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 10.1901 - mae: 2.5445 - val_loss: 5.1534 - val_mae: 2.1595 - learning_rate: 9.3750e-06\n",
      "Epoch 74/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 6.0502 - mae: 2.1638 - val_loss: 6.0028 - val_mae: 2.1335 - learning_rate: 9.3750e-06\n",
      "Epoch 75/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 12.3645 - mae: 2.7265 - val_loss: 6.4305 - val_mae: 2.2298 - learning_rate: 9.3750e-06\n",
      "Epoch 76/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 10.9901 - mae: 2.6258 - val_loss: 11.0790 - val_mae: 2.5523 - learning_rate: 9.3750e-06\n",
      "Epoch 77/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 12.2766 - mae: 2.6249 - val_loss: 7.2619 - val_mae: 2.1772 - learning_rate: 9.3750e-06\n",
      "Epoch 78/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 618ms/step - loss: 26.3683 - mae: 3.6350 - val_loss: 5.0389 - val_mae: 2.1234 - learning_rate: 9.3750e-06\n",
      "Epoch 79/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 9.4647 - mae: 2.4746 - val_loss: 9.8327 - val_mae: 2.5841 - learning_rate: 9.3750e-06\n",
      "Epoch 80/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.9839 - mae: 2.4227 - val_loss: 8.3662 - val_mae: 2.4230 - learning_rate: 9.3750e-06\n",
      "Epoch 81/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 17.3932 - mae: 3.0137 - val_loss: 34.6187 - val_mae: 4.6945 - learning_rate: 9.3750e-06\n",
      "Epoch 82/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 26.1644 - mae: 3.5667 - val_loss: 9.2431 - val_mae: 2.5175 - learning_rate: 9.3750e-06\n",
      "Epoch 83/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 11.6109 - mae: 2.6421 - val_loss: 5.0333 - val_mae: 2.1087 - learning_rate: 9.3750e-06\n",
      "Epoch 84/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 18.0042 - mae: 2.9275 - val_loss: 73.6344 - val_mae: 6.6375 - learning_rate: 9.3750e-06\n",
      "Epoch 85/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 14.2423 - mae: 2.8455 - val_loss: 4.8115 - val_mae: 2.0796 - learning_rate: 9.3750e-06\n",
      "Epoch 86/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 31.6118 - mae: 3.5317 - val_loss: 5.1289 - val_mae: 2.0925 - learning_rate: 9.3750e-06\n",
      "Epoch 87/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 35.3080 - mae: 3.9898 - val_loss: 27.4184 - val_mae: 3.9977 - learning_rate: 9.3750e-06\n",
      "Epoch 88/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 30.2984 - mae: 3.9063 - val_loss: 8.9015 - val_mae: 2.3092 - learning_rate: 9.3750e-06\n",
      "Epoch 89/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 15.6799 - mae: 2.9166 - val_loss: 16.6635 - val_mae: 3.1061 - learning_rate: 9.3750e-06\n",
      "Epoch 90/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 45.3589 - mae: 4.3696 - val_loss: 41.1279 - val_mae: 5.1157 - learning_rate: 9.3750e-06\n",
      "Epoch 91/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 20.4866 - mae: 3.2293 - val_loss: 18.8071 - val_mae: 3.4638 - learning_rate: 9.3750e-06\n",
      "Epoch 92/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 49.7517 - mae: 4.7871 - val_loss: 167.8461 - val_mae: 10.2932 - learning_rate: 9.3750e-06\n",
      "Epoch 93/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 17.3625 - mae: 2.8965 - val_loss: 21.0504 - val_mae: 3.6622 - learning_rate: 4.6875e-06\n",
      "Epoch 94/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 11.9758 - mae: 2.6103 - val_loss: 4.6761 - val_mae: 2.0344 - learning_rate: 4.6875e-06\n",
      "Epoch 95/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 6.1503 - mae: 2.1349 - val_loss: 4.8933 - val_mae: 2.0059 - learning_rate: 4.6875e-06\n",
      "Epoch 96/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 5.3581 - mae: 2.0355 - val_loss: 4.5903 - val_mae: 2.0236 - learning_rate: 4.6875e-06\n",
      "Epoch 97/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 5.2928 - mae: 2.0425 - val_loss: 11.9498 - val_mae: 2.7866 - learning_rate: 4.6875e-06\n",
      "Epoch 98/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 5.6860 - mae: 2.0625 - val_loss: 9.8990 - val_mae: 2.4068 - learning_rate: 4.6875e-06\n",
      "Epoch 99/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 6.7252 - mae: 2.1531 - val_loss: 5.3804 - val_mae: 2.0628 - learning_rate: 4.6875e-06\n",
      "Epoch 100/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 6.0355 - mae: 2.0877 - val_loss: 9.8588 - val_mae: 2.5603 - learning_rate: 4.6875e-06\n",
      "Epoch 101/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 6.6246 - mae: 2.1456 - val_loss: 4.5167 - val_mae: 1.9950 - learning_rate: 4.6875e-06\n",
      "Epoch 102/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 6.9680 - mae: 2.1853 - val_loss: 4.4688 - val_mae: 1.9949 - learning_rate: 4.6875e-06\n",
      "Epoch 103/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 12.0782 - mae: 2.5838 - val_loss: 7.9095 - val_mae: 2.1880 - learning_rate: 4.6875e-06\n",
      "Epoch 104/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 7.4175 - mae: 2.2407 - val_loss: 15.7853 - val_mae: 3.0191 - learning_rate: 4.6875e-06\n",
      "Epoch 105/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 9.4356 - mae: 2.4071 - val_loss: 7.2867 - val_mae: 2.1193 - learning_rate: 4.6875e-06\n",
      "Epoch 106/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 5.7559 - mae: 2.0617 - val_loss: 25.9050 - val_mae: 3.8819 - learning_rate: 4.6875e-06\n",
      "Epoch 107/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 11.4652 - mae: 2.5223 - val_loss: 9.3108 - val_mae: 2.4940 - learning_rate: 4.6875e-06\n",
      "Epoch 108/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 6.0095 - mae: 2.0770 - val_loss: 6.3254 - val_mae: 2.0194 - learning_rate: 4.6875e-06\n",
      "Epoch 109/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 12.5725 - mae: 2.6515 - val_loss: 4.6079 - val_mae: 1.9847 - learning_rate: 4.6875e-06\n",
      "Epoch 110/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 5.5669 - mae: 2.0256 - val_loss: 7.9659 - val_mae: 2.1873 - learning_rate: 2.3438e-06\n",
      "Epoch 111/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 5.5213 - mae: 2.0251 - val_loss: 7.5514 - val_mae: 2.1416 - learning_rate: 2.3438e-06\n",
      "Epoch 112/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 5.4398 - mae: 2.0286 - val_loss: 7.3310 - val_mae: 2.1176 - learning_rate: 2.3438e-06\n",
      "Epoch 113/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 8.0375 - mae: 2.2694 - val_loss: 4.4578 - val_mae: 1.9462 - learning_rate: 2.3438e-06\n",
      "Epoch 114/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 6.5271 - mae: 2.1201 - val_loss: 6.9442 - val_mae: 2.0745 - learning_rate: 2.3438e-06\n",
      "Epoch 115/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 5.3511 - mae: 2.0039 - val_loss: 4.8126 - val_mae: 1.9373 - learning_rate: 2.3438e-06\n",
      "Epoch 116/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 5.3969 - mae: 1.9957 - val_loss: 6.2156 - val_mae: 2.0009 - learning_rate: 2.3438e-06\n",
      "Epoch 117/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 5.0074 - mae: 1.9527 - val_loss: 5.3898 - val_mae: 1.9450 - learning_rate: 2.3438e-06\n",
      "Epoch 118/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 5.4064 - mae: 2.0022 - val_loss: 4.3307 - val_mae: 1.9403 - learning_rate: 2.3438e-06\n",
      "Epoch 119/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 5.8634 - mae: 2.0456 - val_loss: 5.5116 - val_mae: 1.9474 - learning_rate: 2.3438e-06\n",
      "Epoch 120/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 5.7310 - mae: 2.0440 - val_loss: 4.2745 - val_mae: 1.9408 - learning_rate: 2.3438e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/01 13:21:12 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/01 13:21:18 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/12/01 13:21:19 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN6 - MAE: 226.08, RMSE: 431.51, R2: -0.3689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/12/01 13:21:23 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def build_nn6(n_features: int):\n",
    "    inp = keras.Input(shape=(n_features,))\n",
    "\n",
    "    x = layers.Dense(256, activation=\"relu\")(inp)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    x = layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    x = layers.Dense(128, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    x = layers.Dense(64, activation=\"relu\")(x)\n",
    "    out = layers.Dense(1)(x)\n",
    "\n",
    "    model = keras.Model(inputs=inp, outputs=out)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=3e-4),\n",
    "        loss=\"mse\",\n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "mae_nn6 = rmse_nn6 = r2_nn6 = None\n",
    "\n",
    "with mlflow.start_run(run_name=\"NN6_big_dropout_lowLR\"):\n",
    "    mlflow.log_param(\"model_type\", \"NN6_big_dropout_lowLR\")\n",
    "    mlflow.log_param(\"layers\", \"256 -> 256 -> 128 -> 64 -> 1\")\n",
    "    mlflow.log_param(\"learning_rate\", 3e-4)\n",
    "    mlflow.log_param(\"dropout\", \"0.5, 0.5, 0.3\")\n",
    "    mlflow.log_param(\"activation_hidden\", \"ReLU\")\n",
    "\n",
    "    nn6 = build_nn6(X_train_scaled.shape[1])\n",
    "\n",
    "    history6 = nn6.fit(\n",
    "        X_train_scaled, y_train,\n",
    "        validation_split=0.2,\n",
    "        epochs=120,\n",
    "        batch_size=32,\n",
    "        verbose=1,\n",
    "        callbacks=[\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                patience=15,\n",
    "                restore_best_weights=True\n",
    "            ),\n",
    "            keras.callbacks.ReduceLROnPlateau(\n",
    "                patience=7,\n",
    "                factor=0.5\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    mae_nn6, rmse_nn6, r2_nn6 = evaluate_on_real_scale(nn6, X_test_scaled, y_test, prefix=\"NN6\")\n",
    "\n",
    "    mlflow.log_metric(\"MAE_real\", mae_nn6)\n",
    "    mlflow.log_metric(\"RMSE_real\", rmse_nn6)\n",
    "    mlflow.log_metric(\"R2_real\", r2_nn6)\n",
    "\n",
    "    mlflow.keras.log_model(nn6, artifact_path=\"nn6_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "929be8ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NN1_baseline</td>\n",
       "      <td>143.581453</td>\n",
       "      <td>365.632837</td>\n",
       "      <td>0.017195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NN2_deeper_dropout</td>\n",
       "      <td>113.276728</td>\n",
       "      <td>343.430486</td>\n",
       "      <td>0.132929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NN3_deep_bn_dropout</td>\n",
       "      <td>100.087950</td>\n",
       "      <td>322.982270</td>\n",
       "      <td>0.233108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NN4_low_lr_bs64</td>\n",
       "      <td>163.951803</td>\n",
       "      <td>1172.442084</td>\n",
       "      <td>-9.105549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NN5_l2_dropout_arch256</td>\n",
       "      <td>180.164854</td>\n",
       "      <td>718.117926</td>\n",
       "      <td>-2.791130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NN6_big_dropout_lowLR</td>\n",
       "      <td>226.083449</td>\n",
       "      <td>431.509440</td>\n",
       "      <td>-0.368856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model         MAE         RMSE        R2\n",
       "0            NN1_baseline  143.581453   365.632837  0.017195\n",
       "1      NN2_deeper_dropout  113.276728   343.430486  0.132929\n",
       "2     NN3_deep_bn_dropout  100.087950   322.982270  0.233108\n",
       "3         NN4_low_lr_bs64  163.951803  1172.442084 -9.105549\n",
       "4  NN5_l2_dropout_arch256  180.164854   718.117926 -2.791130\n",
       "5   NN6_big_dropout_lowLR  226.083449   431.509440 -0.368856"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_nn_full = pd.DataFrame({\n",
    "    \"Model\": [\n",
    "        \"NN1_baseline\",\n",
    "        \"NN2_deeper_dropout\",\n",
    "        \"NN3_deep_bn_dropout\",\n",
    "        \"NN4_low_lr_bs64\",\n",
    "        \"NN5_l2_dropout_arch256\",\n",
    "        \"NN6_big_dropout_lowLR\"\n",
    "    ],\n",
    "    \"MAE\": [mae_nn1, mae_nn2, mae_nn3, mae_nn4, mae_nn5, mae_nn6],\n",
    "    \"RMSE\": [rmse_nn1, rmse_nn2, rmse_nn3, rmse_nn4, rmse_nn5, rmse_nn6],\n",
    "    \"R2\": [r2_nn1, r2_nn2, r2_nn3, r2_nn4, r2_nn5, r2_nn6]\n",
    "})\n",
    "\n",
    "results_nn_full"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
