{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3db99a7b",
   "metadata": {},
   "source": [
    "Importación y configuración de MLflow:\n",
    "Se cargan todas la librerias y las herramientas para la creación de los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e5145c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.16.2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "\n",
    "print(\"TensorFlow:\", tf.__version__)\n",
    "\n",
    "# Configuración de MLflow (local, sin tracking_uri raro)\n",
    "mlflow.set_experiment(\"airbnb_regresion_nn\")\n",
    "\n",
    "# Activo autolog para Keras (registra automáticamente métricas, parámetros y modelo)\n",
    "mlflow.keras.autolog()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e94f9b5",
   "metadata": {},
   "source": [
    "Carga del data set limpio y entregado por los estudiantes del TEC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "961b7314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>name</th>\n",
       "      <th>host_id</th>\n",
       "      <th>host_name</th>\n",
       "      <th>host_since</th>\n",
       "      <th>host_is_superhost</th>\n",
       "      <th>host_listings_count</th>\n",
       "      <th>host_total_listings_count</th>\n",
       "      <th>host_verifications</th>\n",
       "      <th>...</th>\n",
       "      <th>has_free_street_parking</th>\n",
       "      <th>has_private_entrance</th>\n",
       "      <th>has_essentials</th>\n",
       "      <th>has_heating</th>\n",
       "      <th>has_wifi</th>\n",
       "      <th>has_pets_allowed</th>\n",
       "      <th>has_hot_water</th>\n",
       "      <th>has_self_check_in</th>\n",
       "      <th>has_freezer</th>\n",
       "      <th>has_exercise_equipment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18744501</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>\"Artist´s Creative Residence\" 100m² im Zentrum</td>\n",
       "      <td>129635321</td>\n",
       "      <td>Sylvia</td>\n",
       "      <td>2017-05-09</td>\n",
       "      <td>f</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['email', 'phone']</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23356842</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>\"Bohemian Residency\" (Central &amp; Quiet) * * * * *</td>\n",
       "      <td>150173398</td>\n",
       "      <td>Vincent</td>\n",
       "      <td>2017-09-11</td>\n",
       "      <td>t</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>['email', 'phone']</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>819658084391291386</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>\"Feel at Home\" Flat at the Lerchenauer See</td>\n",
       "      <td>29225873</td>\n",
       "      <td>Skandar</td>\n",
       "      <td>2015-03-12</td>\n",
       "      <td>f</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['email', 'phone']</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34677963</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>\"Little Star\"  Schlafoase im Zentrum</td>\n",
       "      <td>28482431</td>\n",
       "      <td>Adriana</td>\n",
       "      <td>2015-02-28</td>\n",
       "      <td>f</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['email', 'phone']</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34431776</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>\"Moonlight\" Schlafoase mitten im Szenenviertel</td>\n",
       "      <td>28482431</td>\n",
       "      <td>Adriana</td>\n",
       "      <td>2015-02-28</td>\n",
       "      <td>f</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['email', 'phone']</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id       source  \\\n",
       "0            18744501  city scrape   \n",
       "1            23356842  city scrape   \n",
       "2  819658084391291386  city scrape   \n",
       "3            34677963  city scrape   \n",
       "4            34431776  city scrape   \n",
       "\n",
       "                                               name    host_id host_name  \\\n",
       "0    \"Artist´s Creative Residence\" 100m² im Zentrum  129635321    Sylvia   \n",
       "1  \"Bohemian Residency\" (Central & Quiet) * * * * *  150173398   Vincent   \n",
       "2        \"Feel at Home\" Flat at the Lerchenauer See   29225873   Skandar   \n",
       "3              \"Little Star\"  Schlafoase im Zentrum   28482431   Adriana   \n",
       "4    \"Moonlight\" Schlafoase mitten im Szenenviertel   28482431   Adriana   \n",
       "\n",
       "   host_since host_is_superhost  host_listings_count  \\\n",
       "0  2017-05-09                 f                  1.0   \n",
       "1  2017-09-11                 t                  2.0   \n",
       "2  2015-03-12                 f                  1.0   \n",
       "3  2015-02-28                 f                  5.0   \n",
       "4  2015-02-28                 f                  5.0   \n",
       "\n",
       "   host_total_listings_count  host_verifications  ... has_free_street_parking  \\\n",
       "0                        1.0  ['email', 'phone']  ...                       1   \n",
       "1                        3.0  ['email', 'phone']  ...                       1   \n",
       "2                        1.0  ['email', 'phone']  ...                       0   \n",
       "3                        5.0  ['email', 'phone']  ...                       0   \n",
       "4                        5.0  ['email', 'phone']  ...                       0   \n",
       "\n",
       "  has_private_entrance has_essentials has_heating  has_wifi  has_pets_allowed  \\\n",
       "0                    1              1           1         1                 0   \n",
       "1                    1              1           1         1                 0   \n",
       "2                    0              1           1         1                 1   \n",
       "3                    1              1           1         1                 0   \n",
       "4                    1              1           1         1                 0   \n",
       "\n",
       "  has_hot_water has_self_check_in  has_freezer  has_exercise_equipment  \n",
       "0             1                 0            0                       0  \n",
       "1             1                 1            0                       0  \n",
       "2             1                 0            0                       1  \n",
       "3             1                 1            0                       0  \n",
       "4             1                 1            0                       0  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(\"listings_clean_final.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd36aaa",
   "metadata": {},
   "source": [
    "Limpieza de la variable predictoria. La variable 'price' viene como texto \"string\" con símbolos. Se limpia y se transforma en numérico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e55884cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    221.0\n",
       " 1    797.0\n",
       " 2    106.0\n",
       " 3    258.0\n",
       " 4    249.0\n",
       " Name: price, dtype: float64,\n",
       " dtype('float64'))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"price\"] = (\n",
    "    df[\"price\"]\n",
    "    .str.replace(\"$\", \"\", regex=False)\n",
    "    .str.replace(\",\", \"\", regex=False)\n",
    "    .astype(float)\n",
    ")\n",
    "\n",
    "df[\"price\"].head(), df[\"price\"].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09989c1",
   "metadata": {},
   "source": [
    "Hacemos una tranformación logarítmica del precio, ya que este tiene una distribución muy asimétrica. Esto se hace para estabilizar la varianza y mejorar los modelos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dbdc218f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5562.000000\n",
       "mean        5.243958\n",
       "std         0.744214\n",
       "min         2.772589\n",
       "25%         4.727388\n",
       "50%         5.198497\n",
       "75%         5.707110\n",
       "max         9.332912\n",
       "Name: price_log, dtype: float64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"price_log\"] = np.log1p(df[\"price\"])\n",
    "df[\"price_log\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3141e2",
   "metadata": {},
   "source": [
    "Selección de la variables.\n",
    "Seleccionamos las variables numéricas y transformadas anteriormente por el equipo del TEC. Se excluyen columnas textuales y redundantes. Estas variables se usarán para entrenar las redes neuronales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "961a45ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5562, 59), (5562,))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = [\n",
    "    'latitude','longitude','accommodates','bathrooms','bedrooms','beds',\n",
    "    'minimum_nights','maximum_nights','minimum_minimum_nights','maximum_minimum_nights',\n",
    "    'minimum_maximum_nights','maximum_maximum_nights','minimum_nights_avg_ntm',\n",
    "    'maximum_nights_avg_ntm','availability_30','availability_60','availability_90',\n",
    "    'availability_365','number_of_reviews','number_of_reviews_ltm','number_of_reviews_l30d',\n",
    "    'availability_eoy','number_of_reviews_ly','estimated_occupancy_l365d',\n",
    "    'estimated_revenue_l365d',\n",
    "    'calculated_host_listings_count','calculated_host_listings_count_entire_homes',\n",
    "    'calculated_host_listings_count_private_rooms','calculated_host_listings_count_shared_rooms',\n",
    "    'is_Entire_home_apt','is_Hotel_room','is_Private_room','is_Shared_room',\n",
    "    'accommodates_1_to_4','accommodates_5_to_10','accommodates_greater_than_10',\n",
    "    'bathrooms_menor_o_igual_1_5','bathrooms_mas_de_1_5','is_shared_bathroom',\n",
    "    'is_private_bathroom','bedrooms_le_2','bedrooms_3_to_5','bedrooms_gt_6',\n",
    "    'beds_0_to_3','beds_4_to_8','beds_9_to_13','beds_gt_13',\n",
    "    'is_instant_bookable_binary','has_free_street_parking','has_private_entrance',\n",
    "    'has_essentials','has_heating','has_wifi','has_pets_allowed','has_hot_water',\n",
    "    'has_self_check_in','has_freezer','has_exercise_equipment','has_binary'\n",
    "]\n",
    "\n",
    "X = df[feature_cols].copy()\n",
    "y = df[\"price_log\"].copy()\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614c1535",
   "metadata": {},
   "source": [
    "División Train/Test\n",
    "Se dividen los datos en en entrenamiento y prueba y se escalan los features con StandarScaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f750efcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4449, 59), (1113, 59))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled.shape, X_test_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed84fe8",
   "metadata": {},
   "source": [
    "Función auxiliar para evaluar modelos: \n",
    "Defino una función auxiliar para evaluar cada red neuronal en la escala real del precio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e49b3d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_real_scale(model, X_test_scaled, y_test, prefix=\"\"):\n",
    "    # Predicciones en escala log\n",
    "    y_pred_log = model.predict(X_test_scaled).ravel()\n",
    "    \n",
    "    # Pasar a escala real\n",
    "    y_pred = np.expm1(y_pred_log)\n",
    "    y_true = np.expm1(y_test.values)\n",
    "    \n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    if prefix:\n",
    "        print(f\"{prefix} - MAE: {mae:.2f}, RMSE: {rmse:.2f}, R2: {r2:.4f}\")\n",
    "    else:\n",
    "        print(f\"MAE: {mae:.2f}, RMSE: {rmse:.2f}, R2: {r2:.4f}\")\n",
    "    \n",
    "    return mae, rmse, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b1c024",
   "metadata": {},
   "source": [
    "Primer modelo de regresion: NN1 (Red Neuronal 1)\n",
    "Este es el primer modelo de referencia. Uso una arquitectura sencilla (64, 32, 16) con activación ReLU en las capas ocultas y salida lineal para regresión.  \n",
    "Sirve como punto de comparación para evaluar si las arquitecturas posteriores realmente mejoran el desempeño.  \n",
    "El modelo se registra en MLflow con sus parámetros y métricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "66cd7c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025/12/01 15:09:48 WARNING mlflow.keras.autologging: Failed to log dataset information to MLflow. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 20.6816 - mae: 4.0045 - val_loss: 17.8865 - val_mae: 2.8344\n",
      "Epoch 2/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 8.3497 - mae: 2.0345 - val_loss: 17.7916 - val_mae: 2.3509\n",
      "Epoch 3/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 4.6847 - mae: 1.3476 - val_loss: 3.2434 - val_mae: 1.3929\n",
      "Epoch 4/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 2.3855 - mae: 1.0071 - val_loss: 4.4321 - val_mae: 1.5578\n",
      "Epoch 5/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 2.4752 - mae: 1.0017 - val_loss: 1.4284 - val_mae: 0.8775\n",
      "Epoch 6/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 4.3933 - mae: 1.2600 - val_loss: 1.3926 - val_mae: 0.8662\n",
      "Epoch 7/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 2.1457 - mae: 0.9055 - val_loss: 42.7871 - val_mae: 4.6753\n",
      "Epoch 8/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 3.6781 - mae: 0.9943 - val_loss: 1.0528 - val_mae: 0.5792\n",
      "Epoch 9/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.5133 - mae: 0.8007 - val_loss: 0.8736 - val_mae: 0.6969\n",
      "Epoch 10/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.8438 - mae: 0.6221 - val_loss: 0.4268 - val_mae: 0.4395\n",
      "Epoch 11/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.8905 - mae: 0.6371 - val_loss: 0.8900 - val_mae: 0.6781\n",
      "Epoch 12/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.8559 - mae: 0.6236 - val_loss: 0.3486 - val_mae: 0.4268\n",
      "Epoch 13/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.5864 - mae: 0.5373 - val_loss: 0.6641 - val_mae: 0.5835\n",
      "Epoch 14/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.4821 - mae: 0.5067 - val_loss: 0.3499 - val_mae: 0.4413\n",
      "Epoch 15/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 9.4378 - mae: 1.5770 - val_loss: 14.1801 - val_mae: 2.7165\n",
      "Epoch 16/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 26.3225 - mae: 2.7847 - val_loss: 6.1826 - val_mae: 1.8324\n",
      "Epoch 17/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1.9517 - mae: 0.9273 - val_loss: 2.2449 - val_mae: 1.0697\n",
      "Epoch 18/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.6885 - mae: 0.5840 - val_loss: 0.4647 - val_mae: 0.5114\n",
      "Epoch 19/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.6210 - mae: 0.5658 - val_loss: 0.3020 - val_mae: 0.4195\n",
      "Epoch 20/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1.4195 - mae: 0.6757 - val_loss: 0.3063 - val_mae: 0.4164\n",
      "Epoch 21/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.9305 - mae: 0.6307 - val_loss: 1.1863 - val_mae: 0.8289\n",
      "Epoch 22/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.7235 - mae: 0.5634 - val_loss: 1.1241 - val_mae: 0.7764\n",
      "Epoch 23/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.4616 - mae: 0.4937 - val_loss: 0.4598 - val_mae: 0.5193\n",
      "Epoch 24/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.0143 - mae: 0.6653 - val_loss: 1.6413 - val_mae: 0.9023\n",
      "Epoch 25/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 1.3209 - mae: 0.7212 - val_loss: 0.4366 - val_mae: 0.4974\n",
      "Epoch 26/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1.6810 - mae: 0.7740 - val_loss: 7.7655 - val_mae: 2.0440\n",
      "Epoch 27/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.9972 - mae: 0.6934 - val_loss: 0.5577 - val_mae: 0.5347\n",
      "Epoch 28/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.3977 - mae: 0.4723 - val_loss: 0.7376 - val_mae: 0.6298\n",
      "Epoch 29/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 8.7766 - mae: 1.7453 - val_loss: 6.6725 - val_mae: 1.8055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/01 15:10:28 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/01 15:10:35 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/12/01 15:10:35 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN1 - MAE: 110.79, RMSE: 339.58, R2: 0.1523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/12/01 15:10:40 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def build_nn1(n_features: int):\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(64, activation=\"relu\", input_shape=(n_features,)),\n",
    "        layers.Dense(32, activation=\"relu\"),\n",
    "        layers.Dense(16, activation=\"relu\"),\n",
    "        layers.Dense(1)  # salida lineal\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        loss=\"mse\",\n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "mae_nn1 = rmse_nn1 = r2_nn1 = None\n",
    "\n",
    "with mlflow.start_run(run_name=\"NN1_baseline\"):\n",
    "    mlflow.log_param(\"model_type\", \"NN1_baseline\")\n",
    "    mlflow.log_param(\"layers\", \"64 -> 1\")\n",
    "    mlflow.log_param(\"activation_hidden\", \"ReLU\")\n",
    "    mlflow.log_param(\"learning_rate\", 1e-3)\n",
    "    mlflow.log_param(\"batch_size\", 32)\n",
    "    mlflow.log_param(\"epochs_max\", 80)\n",
    "    mlflow.log_param(\"validation_split\", 0.2)\n",
    "    \n",
    "    nn1 = build_nn1(X_train_scaled.shape[1])\n",
    "    \n",
    "    history1 = nn1.fit(\n",
    "        X_train_scaled, y_train,\n",
    "        validation_split=0.2,\n",
    "        epochs=80,\n",
    "        batch_size=32,\n",
    "        verbose=1,\n",
    "        callbacks=[\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                patience=10, restore_best_weights=True\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    mae_nn1, rmse_nn1, r2_nn1 = evaluate_on_real_scale(nn1, X_test_scaled, y_test, prefix=\"NN1\")\n",
    "    \n",
    "    # Logueo métricas en escala real\n",
    "    mlflow.log_metric(\"MAE_real\", mae_nn1)\n",
    "    mlflow.log_metric(\"RMSE_real\", rmse_nn1)\n",
    "    mlflow.log_metric(\"R2_real\", r2_nn1)\n",
    "    \n",
    "    # Guardo el modelo como artefacto explícito (además del autolog)\n",
    "    mlflow.keras.log_model(nn1, artifact_path=\"nn1_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f4b2ae",
   "metadata": {},
   "source": [
    "Segundo modelo de regresión: (NN2)\n",
    "Segundo modelo con dos capas ocultas y un dropout del 30%. Es decir, durante los entrenamientos se apagan aleatoriamente el 30% de las neuronas. Esto ayuda a controlar el sobreajuste y a que prediga patrones más generales y no ruido del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cb3d74b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/01 15:10:41 WARNING mlflow.keras.autologging: Failed to log dataset information to MLflow. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 20.9523 - mae: 4.1222 - val_loss: 11.8026 - val_mae: 2.9982\n",
      "Epoch 2/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 7.6192 - mae: 2.0532 - val_loss: 2.8055 - val_mae: 1.1997\n",
      "Epoch 3/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3.9743 - mae: 1.3809 - val_loss: 3.1080 - val_mae: 0.9544\n",
      "Epoch 4/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 2.7999 - mae: 1.0991 - val_loss: 2.3674 - val_mae: 0.9039\n",
      "Epoch 5/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.8927 - mae: 0.9455 - val_loss: 1.4955 - val_mae: 0.7385\n",
      "Epoch 6/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1.5301 - mae: 0.8660 - val_loss: 1.0671 - val_mae: 0.5612\n",
      "Epoch 7/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.4927 - mae: 0.8433 - val_loss: 0.6810 - val_mae: 0.5241\n",
      "Epoch 8/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.8052 - mae: 0.8553 - val_loss: 2.7211 - val_mae: 1.0947\n",
      "Epoch 9/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.9827 - mae: 0.9564 - val_loss: 1.8034 - val_mae: 0.8111\n",
      "Epoch 10/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.6933 - mae: 0.8984 - val_loss: 0.6333 - val_mae: 0.5224\n",
      "Epoch 11/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.7725 - mae: 0.9034 - val_loss: 1.9919 - val_mae: 0.9796\n",
      "Epoch 12/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1.2750 - mae: 0.8005 - val_loss: 0.9472 - val_mae: 0.5886\n",
      "Epoch 13/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1.1364 - mae: 0.7309 - val_loss: 1.0194 - val_mae: 0.5747\n",
      "Epoch 14/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1.0397 - mae: 0.6950 - val_loss: 0.7422 - val_mae: 0.6508\n",
      "Epoch 15/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.1572 - mae: 0.7611 - val_loss: 0.6379 - val_mae: 0.5420\n",
      "Epoch 16/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.7132 - mae: 0.6254 - val_loss: 1.0924 - val_mae: 0.8067\n",
      "Epoch 17/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.9717 - mae: 0.6892 - val_loss: 0.5627 - val_mae: 0.5423\n",
      "Epoch 18/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 2.3075 - mae: 0.9760 - val_loss: 1.0138 - val_mae: 0.6185\n",
      "Epoch 19/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.1719 - mae: 0.7261 - val_loss: 0.6736 - val_mae: 0.4860\n",
      "Epoch 20/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.8421 - mae: 0.6477 - val_loss: 1.3243 - val_mae: 0.8120\n",
      "Epoch 21/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.6344 - mae: 0.7886 - val_loss: 1.2519 - val_mae: 0.6243\n",
      "Epoch 22/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.9950 - mae: 0.7125 - val_loss: 0.5871 - val_mae: 0.5767\n",
      "Epoch 23/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.1279 - mae: 0.7378 - val_loss: 1.1986 - val_mae: 0.7636\n",
      "Epoch 24/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.9326 - mae: 0.6854 - val_loss: 0.6210 - val_mae: 0.5944\n",
      "Epoch 25/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.1314 - mae: 0.7320 - val_loss: 1.8528 - val_mae: 1.0319\n",
      "Epoch 26/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.3460 - mae: 0.7722 - val_loss: 1.3077 - val_mae: 0.8578\n",
      "Epoch 27/80\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.1498 - mae: 0.7425 - val_loss: 0.7187 - val_mae: 0.5253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/01 15:11:13 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/01 15:11:19 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/12/01 15:11:19 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN2 - MAE: 605.20, RMSE: 10258.41, R2: -772.6373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/12/01 15:11:25 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def build_nn2(n_features: int):\n",
    "    inp = keras.Input(shape=(n_features,))\n",
    "    x = layers.Dense(128, activation=\"relu\")(inp)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(64, activation=\"relu\")(x)\n",
    "    out = layers.Dense(1)(x)\n",
    "    \n",
    "    model = keras.Model(inputs=inp, outputs=out)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        loss=\"mse\",\n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "mae_nn2 = rmse_nn2 = r2_nn2 = None\n",
    "\n",
    "with mlflow.start_run(run_name=\"NN2_deeper_dropout\"):\n",
    "    mlflow.log_param(\"model_type\", \"NN2_deeper_dropout\")\n",
    "    mlflow.log_param(\"layers\", \"128 -> 64 -> 1\")\n",
    "    mlflow.log_param(\"activation_hidden\", \"ReLU\")\n",
    "    mlflow.log_param(\"dropout_first\", 0.3)\n",
    "    mlflow.log_param(\"learning_rate\", 1e-3)\n",
    "    mlflow.log_param(\"batch_size\", 32)\n",
    "    mlflow.log_param(\"epochs_max\", 80)\n",
    "    mlflow.log_param(\"validation_split\", 0.2)\n",
    "    \n",
    "    nn2 = build_nn2(X_train_scaled.shape[1])\n",
    "    \n",
    "    history2 = nn2.fit(\n",
    "        X_train_scaled, y_train,\n",
    "        validation_split=0.2,\n",
    "        epochs=80,\n",
    "        batch_size=32,\n",
    "        verbose=1,\n",
    "        callbacks=[\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                patience=10, restore_best_weights=True\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    mae_nn2, rmse_nn2, r2_nn2 = evaluate_on_real_scale(nn2, X_test_scaled, y_test, prefix=\"NN2\")\n",
    "    \n",
    "    mlflow.log_metric(\"MAE_real\", mae_nn2)\n",
    "    mlflow.log_metric(\"RMSE_real\", rmse_nn2)\n",
    "    mlflow.log_metric(\"R2_real\", r2_nn2)\n",
    "    \n",
    "    mlflow.keras.log_model(nn2, artifact_path=\"nn2_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b64052f",
   "metadata": {},
   "source": [
    "Tercer modelo de redes neuronales: (NN3)\n",
    "Se hace un tercer con modelo con mayor profundidad (deep), batch de normalización (bn), regularización y activación ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bee260fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/01 15:11:26 WARNING mlflow.keras.autologging: Failed to log dataset information to MLflow. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - loss: 23.7246 - mae: 4.6573 - val_loss: 16.7798 - val_mae: 4.0463 - learning_rate: 5.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 12.2597 - mae: 3.1795 - val_loss: 5.2633 - val_mae: 2.1854 - learning_rate: 5.0000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 5.3788 - mae: 1.8377 - val_loss: 1.1897 - val_mae: 0.9504 - learning_rate: 5.0000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 3.7669 - mae: 1.4847 - val_loss: 0.8573 - val_mae: 0.7612 - learning_rate: 5.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 3.3790 - mae: 1.3898 - val_loss: 0.7786 - val_mae: 0.7262 - learning_rate: 5.0000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 3.1019 - mae: 1.3328 - val_loss: 1.5453 - val_mae: 0.9972 - learning_rate: 5.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 2.6686 - mae: 1.2502 - val_loss: 0.7114 - val_mae: 0.6765 - learning_rate: 5.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 2.4213 - mae: 1.1828 - val_loss: 1.3238 - val_mae: 0.9177 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 2.0349 - mae: 1.0901 - val_loss: 0.6836 - val_mae: 0.6341 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 1.7297 - mae: 1.0023 - val_loss: 0.5616 - val_mae: 0.5798 - learning_rate: 5.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 1.1822 - mae: 0.8315 - val_loss: 0.5118 - val_mae: 0.5441 - learning_rate: 5.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.9696 - mae: 0.7595 - val_loss: 0.4118 - val_mae: 0.4922 - learning_rate: 5.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.6226 - mae: 0.6072 - val_loss: 0.4518 - val_mae: 0.5223 - learning_rate: 5.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.4782 - mae: 0.5365 - val_loss: 0.3073 - val_mae: 0.4249 - learning_rate: 5.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.4589 - mae: 0.5242 - val_loss: 0.3809 - val_mae: 0.4919 - learning_rate: 5.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.3963 - mae: 0.4900 - val_loss: 0.4058 - val_mae: 0.5143 - learning_rate: 5.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.5960 - mae: 0.5943 - val_loss: 0.5058 - val_mae: 0.5804 - learning_rate: 5.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.4403 - mae: 0.5134 - val_loss: 0.7877 - val_mae: 0.7321 - learning_rate: 5.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.4106 - mae: 0.4936 - val_loss: 0.5617 - val_mae: 0.6079 - learning_rate: 5.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.3279 - mae: 0.4426 - val_loss: 0.2764 - val_mae: 0.4070 - learning_rate: 2.5000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.3815 - mae: 0.4773 - val_loss: 0.2810 - val_mae: 0.4024 - learning_rate: 2.5000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.3236 - mae: 0.4395 - val_loss: 0.2755 - val_mae: 0.4059 - learning_rate: 2.5000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.3076 - mae: 0.4334 - val_loss: 0.2754 - val_mae: 0.4043 - learning_rate: 2.5000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.3140 - mae: 0.4381 - val_loss: 0.2827 - val_mae: 0.4080 - learning_rate: 2.5000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.3456 - mae: 0.4596 - val_loss: 0.4030 - val_mae: 0.4870 - learning_rate: 2.5000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.3354 - mae: 0.4488 - val_loss: 0.2775 - val_mae: 0.4085 - learning_rate: 2.5000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.3586 - mae: 0.4642 - val_loss: 0.3622 - val_mae: 0.4755 - learning_rate: 2.5000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.3477 - mae: 0.4571 - val_loss: 0.2960 - val_mae: 0.4225 - learning_rate: 2.5000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.3296 - mae: 0.4444 - val_loss: 0.2796 - val_mae: 0.4012 - learning_rate: 1.2500e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.3110 - mae: 0.4311 - val_loss: 0.2895 - val_mae: 0.4201 - learning_rate: 1.2500e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.2985 - mae: 0.4241 - val_loss: 0.3241 - val_mae: 0.4404 - learning_rate: 1.2500e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.2984 - mae: 0.4255 - val_loss: 0.2925 - val_mae: 0.4115 - learning_rate: 1.2500e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.3218 - mae: 0.4427 - val_loss: 0.2794 - val_mae: 0.4033 - learning_rate: 1.2500e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.2900 - mae: 0.4165 - val_loss: 0.2801 - val_mae: 0.3999 - learning_rate: 6.2500e-05\n",
      "Epoch 35/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.3032 - mae: 0.4287 - val_loss: 0.2818 - val_mae: 0.4113 - learning_rate: 6.2500e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/01 15:12:40 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/01 15:12:48 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN3 - MAE: 98.88, RMSE: 318.99, R2: 0.2519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/01 15:12:48 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "\u001b[31m2025/12/01 15:12:53 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def build_nn3(n_features: int):\n",
    "    inp = keras.Input(shape=(n_features,))\n",
    "    \n",
    "    x = layers.Dense(256, activation=\"relu\")(inp)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    \n",
    "    x = layers.Dense(128, activation=\"relu\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    x = layers.Dense(64, activation=\"relu\")(x)\n",
    "    \n",
    "    out = layers.Dense(1)(x)\n",
    "    \n",
    "    model = keras.Model(inputs=inp, outputs=out)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=5e-4),\n",
    "        loss=\"mse\",\n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "mae_nn3 = rmse_nn3 = r2_nn3 = None\n",
    "\n",
    "with mlflow.start_run(run_name=\"NN3_deep_bn_dropout\"):\n",
    "    mlflow.log_param(\"model_type\", \"NN3_deep_bn_dropout\")\n",
    "    mlflow.log_param(\"layers\", \"256 -> 128 -> 64 -> 1\")\n",
    "    mlflow.log_param(\"activation_hidden\", \"ReLU\")\n",
    "    mlflow.log_param(\"dropout\", \"0.4, 0.3\")\n",
    "    mlflow.log_param(\"batchnorm\", True)\n",
    "    mlflow.log_param(\"learning_rate\", 5e-4)\n",
    "    mlflow.log_param(\"batch_size\", 32)\n",
    "    mlflow.log_param(\"epochs_max\", 100)\n",
    "    mlflow.log_param(\"validation_split\", 0.2)\n",
    "    \n",
    "    nn3 = build_nn3(X_train_scaled.shape[1])\n",
    "    \n",
    "    history3 = nn3.fit(\n",
    "        X_train_scaled, y_train,\n",
    "        validation_split=0.2,\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        verbose=1,\n",
    "        callbacks=[\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                patience=12, restore_best_weights=True\n",
    "            ),\n",
    "            keras.callbacks.ReduceLROnPlateau(\n",
    "                patience=5, factor=0.5\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    mae_nn3, rmse_nn3, r2_nn3 = evaluate_on_real_scale(nn3, X_test_scaled, y_test, prefix=\"NN3\")\n",
    "    \n",
    "    mlflow.log_metric(\"MAE_real\", mae_nn3)\n",
    "    mlflow.log_metric(\"RMSE_real\", rmse_nn3)\n",
    "    mlflow.log_metric(\"R2_real\", r2_nn3)\n",
    "    \n",
    "    mlflow.keras.log_model(nn3, artifact_path=\"nn3_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6915a06a",
   "metadata": {},
   "source": [
    "Construyo otra red neuronal eliminando una capa en comparacion con la red anterior a ver qué sucede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5a4e7d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/01 15:12:53 WARNING mlflow.keras.autologging: Failed to log dataset information to MLflow. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - loss: 23.6840 - mae: 4.6051 - val_loss: 15.6814 - val_mae: 3.9059 - learning_rate: 5.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 11.8758 - mae: 3.0881 - val_loss: 4.9607 - val_mae: 2.1189 - learning_rate: 5.0000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 5.7963 - mae: 1.9288 - val_loss: 3.1286 - val_mae: 1.4117 - learning_rate: 5.0000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 4.3237 - mae: 1.6255 - val_loss: 0.9570 - val_mae: 0.8126 - learning_rate: 5.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 3.6807 - mae: 1.4538 - val_loss: 1.3276 - val_mae: 0.9125 - learning_rate: 5.0000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 3.5155 - mae: 1.4174 - val_loss: 1.0468 - val_mae: 0.8008 - learning_rate: 5.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 3.1333 - mae: 1.3487 - val_loss: 0.8078 - val_mae: 0.7246 - learning_rate: 5.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.5336 - mae: 1.2121 - val_loss: 0.7299 - val_mae: 0.6972 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 2.1379 - mae: 1.1064 - val_loss: 0.9045 - val_mae: 0.7540 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 1.6316 - mae: 0.9806 - val_loss: 0.5762 - val_mae: 0.5881 - learning_rate: 5.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 1.1411 - mae: 0.8154 - val_loss: 1.1304 - val_mae: 0.8476 - learning_rate: 5.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.8475 - mae: 0.7020 - val_loss: 0.4039 - val_mae: 0.4820 - learning_rate: 5.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.5563 - mae: 0.5705 - val_loss: 0.3726 - val_mae: 0.4668 - learning_rate: 5.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.5595 - mae: 0.5728 - val_loss: 0.4222 - val_mae: 0.4924 - learning_rate: 5.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.4442 - mae: 0.5188 - val_loss: 0.4478 - val_mae: 0.5462 - learning_rate: 5.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.3998 - mae: 0.4911 - val_loss: 0.3029 - val_mae: 0.4370 - learning_rate: 5.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.4074 - mae: 0.4983 - val_loss: 0.4038 - val_mae: 0.5147 - learning_rate: 5.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.3478 - mae: 0.4617 - val_loss: 0.2822 - val_mae: 0.4064 - learning_rate: 5.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.3935 - mae: 0.4857 - val_loss: 0.2801 - val_mae: 0.4053 - learning_rate: 5.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.4622 - mae: 0.5201 - val_loss: 0.3422 - val_mae: 0.4634 - learning_rate: 5.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.3623 - mae: 0.4693 - val_loss: 0.3109 - val_mae: 0.4409 - learning_rate: 5.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.3689 - mae: 0.4714 - val_loss: 0.4048 - val_mae: 0.4845 - learning_rate: 5.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.3592 - mae: 0.4664 - val_loss: 0.3748 - val_mae: 0.4845 - learning_rate: 5.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.4128 - mae: 0.4986 - val_loss: 0.4231 - val_mae: 0.4770 - learning_rate: 5.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.3240 - mae: 0.4401 - val_loss: 0.2894 - val_mae: 0.4181 - learning_rate: 2.5000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.3413 - mae: 0.4508 - val_loss: 0.2781 - val_mae: 0.4016 - learning_rate: 2.5000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.3452 - mae: 0.4560 - val_loss: 0.2976 - val_mae: 0.4122 - learning_rate: 2.5000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.3728 - mae: 0.4746 - val_loss: 0.2858 - val_mae: 0.4099 - learning_rate: 2.5000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.3413 - mae: 0.4575 - val_loss: 0.3043 - val_mae: 0.4278 - learning_rate: 2.5000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.3090 - mae: 0.4314 - val_loss: 0.3024 - val_mae: 0.4051 - learning_rate: 2.5000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.3300 - mae: 0.4443 - val_loss: 0.3482 - val_mae: 0.4340 - learning_rate: 2.5000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.3042 - mae: 0.4312 - val_loss: 0.3151 - val_mae: 0.4212 - learning_rate: 1.2500e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.2985 - mae: 0.4235 - val_loss: 0.2883 - val_mae: 0.4134 - learning_rate: 1.2500e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.3321 - mae: 0.4413 - val_loss: 0.2996 - val_mae: 0.4143 - learning_rate: 1.2500e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.2803 - mae: 0.4103 - val_loss: 0.2952 - val_mae: 0.4162 - learning_rate: 1.2500e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.2926 - mae: 0.4207 - val_loss: 0.3060 - val_mae: 0.4061 - learning_rate: 1.2500e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.2873 - mae: 0.4158 - val_loss: 0.2847 - val_mae: 0.4036 - learning_rate: 6.2500e-05\n",
      "Epoch 38/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.2880 - mae: 0.4184 - val_loss: 0.2962 - val_mae: 0.4142 - learning_rate: 6.2500e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/01 15:14:14 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "NNJD - MAE: 99.47, RMSE: 320.65, R2: 0.2441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/01 15:14:21 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/12/01 15:14:21 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "\u001b[31m2025/12/01 15:14:27 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def build_nnJD(n_features: int):\n",
    "    inp = keras.Input(shape=(n_features,))\n",
    "    \n",
    "    x = layers.Dense(128, activation=\"relu\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    x = layers.Dense(64, activation=\"relu\")(x)\n",
    "    \n",
    "    out = layers.Dense(1)(x)\n",
    "    \n",
    "    model = keras.Model(inputs=inp, outputs=out)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=5e-4),\n",
    "        loss=\"mse\",\n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "mae_nnJD = rmse_nnJD = r2_nnJD = None\n",
    "\n",
    "with mlflow.start_run(run_name=\"NNJD_128_bn_dropout\"):\n",
    "    mlflow.log_param(\"model_type\", \"NNJD_128_bn_dropout\")\n",
    "    mlflow.log_param(\"layers\", \"256 -> 128 -> 64 -> 1\")\n",
    "    mlflow.log_param(\"activation_hidden\", \"ReLU\")\n",
    "    mlflow.log_param(\"dropout\", \"0.4, 0.3\")\n",
    "    mlflow.log_param(\"batchnorm\", True)\n",
    "    mlflow.log_param(\"learning_rate\", 5e-4)\n",
    "    mlflow.log_param(\"batch_size\", 32)\n",
    "    mlflow.log_param(\"epochs_max\", 100)\n",
    "    mlflow.log_param(\"validation_split\", 0.2)\n",
    "    \n",
    "    nnJD = build_nn3(X_train_scaled.shape[1])\n",
    "    \n",
    "    history3 = nnJD.fit(\n",
    "        X_train_scaled, y_train,\n",
    "        validation_split=0.2,\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        verbose=1,\n",
    "        callbacks=[\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                patience=12, restore_best_weights=True\n",
    "            ),\n",
    "            keras.callbacks.ReduceLROnPlateau(\n",
    "                patience=5, factor=0.5\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    mae_nnJD, rmse_nnJD, r2_nnJD = evaluate_on_real_scale(nnJD, X_test_scaled, y_test, prefix=\"NNJD\")\n",
    "    \n",
    "    mlflow.log_metric(\"MAE_real\", mae_nnJD)\n",
    "    mlflow.log_metric(\"RMSE_real\", rmse_nnJD)\n",
    "    mlflow.log_metric(\"R2_real\", r2_nnJD)\n",
    "    \n",
    "    mlflow.keras.log_model(nnJD, artifact_path=\"nnjd_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c30251",
   "metadata": {},
   "source": [
    "Comparación de modelos neuronales\n",
    "Se imprimen los resultados de las 3 redes neuronales y se puede evidenciar que la de menor MSE y mayor R2 es la NN3. Esto se debe a la construcción de una red mas profunda, con capa de normalización, y dropout. Las anteriores ayudan a entrenar mejor al modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7d3e19ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NN1_baseline</td>\n",
       "      <td>110.792830</td>\n",
       "      <td>339.576092</td>\n",
       "      <td>0.152282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NN2_deeper_dropout</td>\n",
       "      <td>605.196646</td>\n",
       "      <td>10258.411950</td>\n",
       "      <td>-772.637290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NN3_deep_bn_dropout</td>\n",
       "      <td>98.876599</td>\n",
       "      <td>318.992990</td>\n",
       "      <td>0.251935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NNJD_128_bn_dropout</td>\n",
       "      <td>99.472153</td>\n",
       "      <td>320.653136</td>\n",
       "      <td>0.244128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model         MAE          RMSE          R2\n",
       "0         NN1_baseline  110.792830    339.576092    0.152282\n",
       "1   NN2_deeper_dropout  605.196646  10258.411950 -772.637290\n",
       "2  NN3_deep_bn_dropout   98.876599    318.992990    0.251935\n",
       "3  NNJD_128_bn_dropout   99.472153    320.653136    0.244128"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_nn = pd.DataFrame({\n",
    "    \"Model\": [\"NN1_baseline\", \"NN2_deeper_dropout\", \"NN3_deep_bn_dropout\",\"NNJD_128_bn_dropout\"],\n",
    "    \"MAE\": [mae_nn1, mae_nn2, mae_nn3, mae_nnJD],\n",
    "    \"RMSE\": [rmse_nn1, rmse_nn2, rmse_nn3, rmse_nnJD],\n",
    "    \"R2\": [r2_nn1, r2_nn2, r2_nn3, r2_nnJD]\n",
    "})\n",
    "\n",
    "results_nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cff3080",
   "metadata": {},
   "source": [
    "Selección del mejor modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fe826f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model    NN3_deep_bn_dropout\n",
       "MAE                98.876599\n",
       "RMSE               318.99299\n",
       "R2                  0.251935\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_row = results_nn.iloc[results_nn[\"MAE\"].idxmin()]\n",
    "best_row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a24230",
   "metadata": {},
   "source": [
    "Ampliación en la búsqueda de hiperparámetros:\n",
    "- Uso un batch size más pequeño (16), lo que introduce más ruido estocástico.\n",
    "- Aumento el learning rate a 0.01.\n",
    "La arquitectura es intermedia (128, 64, 32) con activación ReLU. El objetivo es ver si una tasa de aprendizaje más agresiva mejora o empeora el desempeño."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "18f4571e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/01 15:14:27 WARNING mlflow.keras.autologging: Failed to log dataset information to MLflow. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 26.1896 - mae: 4.8472 - val_loss: 22.9919 - val_mae: 4.4557\n",
      "Epoch 2/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 19.4585 - mae: 4.1178 - val_loss: 16.5327 - val_mae: 3.8087\n",
      "Epoch 3/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 13.2066 - mae: 3.4469 - val_loss: 12.1147 - val_mae: 3.1237\n",
      "Epoch 4/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 10.7984 - mae: 2.8563 - val_loss: 11.7621 - val_mae: 2.4385\n",
      "Epoch 5/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 7.1038 - mae: 2.1962 - val_loss: 7.3379 - val_mae: 1.8093\n",
      "Epoch 6/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 8.2375 - mae: 2.0134 - val_loss: 16.1394 - val_mae: 3.2076\n",
      "Epoch 7/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 4.6230 - mae: 1.5188 - val_loss: 2.8493 - val_mae: 1.0704\n",
      "Epoch 8/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 74.2040 - mae: 4.6230 - val_loss: 15.5100 - val_mae: 2.4626\n",
      "Epoch 9/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 5.2419 - mae: 1.3527 - val_loss: 1.8537 - val_mae: 1.0212\n",
      "Epoch 10/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1.9952 - mae: 0.9342 - val_loss: 5.5502 - val_mae: 1.4652\n",
      "Epoch 11/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 2.1376 - mae: 0.9799 - val_loss: 1.8388 - val_mae: 0.7532\n",
      "Epoch 12/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.1466 - mae: 0.7145 - val_loss: 1.4351 - val_mae: 0.9107\n",
      "Epoch 13/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1.5626 - mae: 0.8638 - val_loss: 2.7153 - val_mae: 0.9799\n",
      "Epoch 14/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 3.5743 - mae: 1.2464 - val_loss: 3.5409 - val_mae: 1.1537\n",
      "Epoch 15/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 2.3959 - mae: 1.0214 - val_loss: 1.7850 - val_mae: 1.0354\n",
      "Epoch 16/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1.7588 - mae: 0.8711 - val_loss: 0.9926 - val_mae: 0.6142\n",
      "Epoch 17/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 2.8441 - mae: 1.1341 - val_loss: 2.1550 - val_mae: 1.1338\n",
      "Epoch 18/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 2.9403 - mae: 1.1306 - val_loss: 7.2920 - val_mae: 2.0563\n",
      "Epoch 19/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 8.1574 - mae: 1.6790 - val_loss: 9.2019 - val_mae: 2.3233\n",
      "Epoch 20/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 4.3038 - mae: 1.3211 - val_loss: 0.5610 - val_mae: 0.5436\n",
      "Epoch 21/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1.5004 - mae: 0.8602 - val_loss: 0.6990 - val_mae: 0.5582\n",
      "Epoch 22/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1.8476 - mae: 0.8628 - val_loss: 0.9014 - val_mae: 0.6365\n",
      "Epoch 23/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.8531 - mae: 0.8164 - val_loss: 3.8917 - val_mae: 1.3616\n",
      "Epoch 24/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 85.4787 - mae: 5.7596 - val_loss: 201.9521 - val_mae: 10.2136\n",
      "Epoch 25/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 93.2999 - mae: 5.1505 - val_loss: 0.7466 - val_mae: 0.6652\n",
      "Epoch 26/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.6348 - mae: 0.5752 - val_loss: 0.4465 - val_mae: 0.5096\n",
      "Epoch 27/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.5942 - mae: 0.5600 - val_loss: 0.3730 - val_mae: 0.4658\n",
      "Epoch 28/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.4357 - mae: 0.4923 - val_loss: 0.3416 - val_mae: 0.4465\n",
      "Epoch 29/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.4103 - mae: 0.4752 - val_loss: 0.3967 - val_mae: 0.4833\n",
      "Epoch 30/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.3900 - mae: 0.4658 - val_loss: 0.7950 - val_mae: 0.6556\n",
      "Epoch 31/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.4860 - mae: 0.5081 - val_loss: 0.3369 - val_mae: 0.4461\n",
      "Epoch 32/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.3743 - mae: 0.4571 - val_loss: 0.3471 - val_mae: 0.4527\n",
      "Epoch 33/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.5263 - mae: 0.5360 - val_loss: 0.7153 - val_mae: 0.6189\n",
      "Epoch 34/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.4360 - mae: 0.4944 - val_loss: 0.3258 - val_mae: 0.4321\n",
      "Epoch 35/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.4704 - mae: 0.5042 - val_loss: 0.8668 - val_mae: 0.7036\n",
      "Epoch 36/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.6433 - mae: 0.5855 - val_loss: 0.3144 - val_mae: 0.4271\n",
      "Epoch 37/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.4268 - mae: 0.4887 - val_loss: 0.3311 - val_mae: 0.4346\n",
      "Epoch 38/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.3722 - mae: 0.4560 - val_loss: 0.4806 - val_mae: 0.5302\n",
      "Epoch 39/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.6706 - mae: 0.5881 - val_loss: 0.3771 - val_mae: 0.4612\n",
      "Epoch 40/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.5772 - mae: 0.5560 - val_loss: 0.3051 - val_mae: 0.4250\n",
      "Epoch 41/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.5460 - mae: 0.5342 - val_loss: 0.3135 - val_mae: 0.4288\n",
      "Epoch 42/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.3214 - mae: 0.4284 - val_loss: 0.9371 - val_mae: 0.7059\n",
      "Epoch 43/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.3594 - mae: 0.4499 - val_loss: 0.3698 - val_mae: 0.4682\n",
      "Epoch 44/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.4175 - mae: 0.4851 - val_loss: 0.5975 - val_mae: 0.5914\n",
      "Epoch 45/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1.4064 - mae: 0.8066 - val_loss: 1.0832 - val_mae: 0.7695\n",
      "Epoch 46/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.4679 - mae: 0.4956 - val_loss: 0.3168 - val_mae: 0.4301\n",
      "Epoch 47/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.4714 - mae: 0.5123 - val_loss: 0.3010 - val_mae: 0.4221\n",
      "Epoch 48/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.3991 - mae: 0.4777 - val_loss: 0.3262 - val_mae: 0.4397\n",
      "Epoch 49/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.3736 - mae: 0.4586 - val_loss: 0.3166 - val_mae: 0.4270\n",
      "Epoch 50/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.7432 - mae: 0.5980 - val_loss: 1.3077 - val_mae: 0.8519\n",
      "Epoch 51/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.6732 - mae: 0.6004 - val_loss: 0.9971 - val_mae: 0.7305\n",
      "Epoch 52/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 2.0562 - mae: 0.9537 - val_loss: 12.3929 - val_mae: 2.4949\n",
      "Epoch 53/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 6.5702 - mae: 1.5704 - val_loss: 3.4343 - val_mae: 1.2709\n",
      "Epoch 54/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 43.5935 - mae: 4.3420 - val_loss: 89.2319 - val_mae: 6.7505\n",
      "Epoch 55/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 313.2805 - mae: 10.9958 - val_loss: 136.2901 - val_mae: 8.1470\n",
      "Epoch 56/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 15.1662 - mae: 2.3423 - val_loss: 2.5323 - val_mae: 0.7748\n",
      "Epoch 57/80\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 3.9263 - mae: 1.2399 - val_loss: 3.4563 - val_mae: 1.3844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/01 15:15:04 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/01 15:15:11 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/12/01 15:15:11 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN4 - MAE: 117.50, RMSE: 351.99, R2: 0.0892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/12/01 15:15:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def build_nn4(n_features: int):\n",
    "    inp = keras.Input(shape=(n_features,))\n",
    "    x = layers.Dense(128, activation=\"relu\")(inp)\n",
    "    x = layers.Dense(64, activation=\"relu\")(x)\n",
    "    x = layers.Dense(32, activation=\"relu\")(x)\n",
    "    out = layers.Dense(1)(x)\n",
    "\n",
    "    model = keras.Model(inputs=inp, outputs=out)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=5e-4),\n",
    "        loss=\"mse\",\n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "mae_nn4 = rmse_nn4 = r2_nn4 = None\n",
    "\n",
    "with mlflow.start_run(run_name=\"NN4_low_lr_bs64\"):\n",
    "    mlflow.log_param(\"model_type\", \"NN4_low_lr_bs64\")\n",
    "    mlflow.log_param(\"layers\", \"128 -> 64 -> 32 -> 1\")\n",
    "    mlflow.log_param(\"learning_rate\", 5e-4)\n",
    "    mlflow.log_param(\"batch_size\", 64)\n",
    "    mlflow.log_param(\"activation_hidden\", \"ReLU\")\n",
    "\n",
    "    nn4 = build_nn4(X_train_scaled.shape[1])\n",
    "\n",
    "    history4 = nn4.fit(\n",
    "        X_train_scaled, y_train,\n",
    "        validation_split=0.2,\n",
    "        epochs=80,\n",
    "        batch_size=64,\n",
    "        verbose=1,\n",
    "        callbacks=[\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                patience=10,\n",
    "                restore_best_weights=True\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    mae_nn4, rmse_nn4, r2_nn4 = evaluate_on_real_scale(nn4, X_test_scaled, y_test, prefix=\"NN4\")\n",
    "\n",
    "    mlflow.log_metric(\"MAE_real\", mae_nn4)\n",
    "    mlflow.log_metric(\"RMSE_real\", rmse_nn4)\n",
    "    mlflow.log_metric(\"R2_real\", r2_nn4)\n",
    "\n",
    "    mlflow.keras.log_model(nn4, artifact_path=\"nn4_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1172f5",
   "metadata": {},
   "source": [
    "Modelo NN5 – Red ancha con L2 y dropout\n",
    "En este modelo uso una arquitectura más grande que NN4 (256–128–64) e incluyo:\n",
    "- Regularización L2 (1e-4) para reducir sobreajuste.\n",
    "- Dropout del 20%.\n",
    "- Learning rate de 0.0008.\n",
    "\n",
    "El objetivo es evaluar si una red más ancha con regularización logra un mejor desempeño que las anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fc58c49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/01 15:15:17 WARNING mlflow.keras.autologging: Failed to log dataset information to MLflow. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 17.5958 - mae: 3.6192 - val_loss: 6.8638 - val_mae: 1.8706\n",
      "Epoch 2/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 23.3489 - mae: 2.9359 - val_loss: 7.3361 - val_mae: 1.8600\n",
      "Epoch 3/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 21.8408 - mae: 2.8174 - val_loss: 8.5958 - val_mae: 2.1144\n",
      "Epoch 4/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 162.3613 - mae: 6.1742 - val_loss: 7.6571 - val_mae: 2.1233\n",
      "Epoch 5/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 11.1026 - mae: 1.9683 - val_loss: 36.5355 - val_mae: 4.3790\n",
      "Epoch 6/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 157.5822 - mae: 5.7675 - val_loss: 2.0374 - val_mae: 1.0426\n",
      "Epoch 7/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 8.5046 - mae: 1.7464 - val_loss: 13.4187 - val_mae: 2.6961\n",
      "Epoch 8/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 7.5796 - mae: 1.6869 - val_loss: 1.4656 - val_mae: 0.8649\n",
      "Epoch 9/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 10.9681 - mae: 1.9871 - val_loss: 0.8974 - val_mae: 0.6486\n",
      "Epoch 10/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 11.3346 - mae: 2.0354 - val_loss: 41.9545 - val_mae: 4.7983\n",
      "Epoch 11/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 61.5266 - mae: 4.4048 - val_loss: 182.6616 - val_mae: 10.1450\n",
      "Epoch 12/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 378.8286 - mae: 10.7978 - val_loss: 15.4890 - val_mae: 2.9976\n",
      "Epoch 13/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 37.5907 - mae: 3.6450 - val_loss: 5.5198 - val_mae: 1.7404\n",
      "Epoch 14/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 21.0278 - mae: 2.7330 - val_loss: 11.9998 - val_mae: 2.5848\n",
      "Epoch 15/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 267.3073 - mae: 7.6184 - val_loss: 1.1516 - val_mae: 0.7051\n",
      "Epoch 16/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 8.7438 - mae: 1.8264 - val_loss: 1.5651 - val_mae: 0.8686\n",
      "Epoch 17/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 9.7121 - mae: 1.9035 - val_loss: 4.4395 - val_mae: 1.5078\n",
      "Epoch 18/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 8.9375 - mae: 1.8714 - val_loss: 2.0848 - val_mae: 0.9423\n",
      "Epoch 19/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 81.2491 - mae: 4.5771 - val_loss: 0.8400 - val_mae: 0.6109\n",
      "Epoch 20/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 11.7212 - mae: 2.1153 - val_loss: 11.4044 - val_mae: 2.5330\n",
      "Epoch 21/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 11.2592 - mae: 1.9593 - val_loss: 49.2859 - val_mae: 5.3401\n",
      "Epoch 22/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 513.2209 - mae: 12.6123 - val_loss: 25.8874 - val_mae: 3.6216\n",
      "Epoch 23/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 97.5818 - mae: 5.3936 - val_loss: 37.3200 - val_mae: 4.6566\n",
      "Epoch 24/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 19.0145 - mae: 2.5598 - val_loss: 1.2654 - val_mae: 0.7539\n",
      "Epoch 25/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 20.1878 - mae: 2.5640 - val_loss: 6.9212 - val_mae: 1.8811\n",
      "Epoch 26/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 99.6884 - mae: 5.1027 - val_loss: 9.7919 - val_mae: 2.3491\n",
      "Epoch 27/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 19.4233 - mae: 2.4800 - val_loss: 4.3194 - val_mae: 1.5163\n",
      "Epoch 28/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 43.5002 - mae: 3.6277 - val_loss: 12.8794 - val_mae: 2.6811\n",
      "Epoch 29/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 388.3265 - mae: 11.0260 - val_loss: 4.8120 - val_mae: 1.6612\n",
      "Epoch 30/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 78.4137 - mae: 4.6199 - val_loss: 1.8228 - val_mae: 0.9365\n",
      "Epoch 31/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 10.2546 - mae: 2.0016 - val_loss: 0.9033 - val_mae: 0.6336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/01 15:16:03 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/01 15:16:09 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/12/01 15:16:09 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN5 - MAE: 222.09, RMSE: 2095.75, R2: -31.2892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/12/01 15:16:15 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "\n",
    "def build_nn5(n_features: int):\n",
    "    l2_reg = regularizers.l2(1e-4)\n",
    "\n",
    "    inp = keras.Input(shape=(n_features,))\n",
    "    x = layers.Dense(256, activation=\"relu\", kernel_regularizer=l2_reg)(inp)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Dense(128, activation=\"relu\", kernel_regularizer=l2_reg)(x)\n",
    "    x = layers.Dense(64, activation=\"relu\", kernel_regularizer=l2_reg)(x)\n",
    "    out = layers.Dense(1)(x)\n",
    "\n",
    "    model = keras.Model(inputs=inp, outputs=out)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=8e-4),\n",
    "        loss=\"mse\",\n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "mae_nn5 = rmse_nn5 = r2_nn5 = None\n",
    "\n",
    "with mlflow.start_run(run_name=\"NN5_l2_dropout_arch256\"):\n",
    "    mlflow.log_param(\"model_type\", \"NN5_l2_dropout_arch256\")\n",
    "    mlflow.log_param(\"layers\", \"256 -> 128 -> 64 -> 1\")\n",
    "    mlflow.log_param(\"learning_rate\", 8e-4)\n",
    "    mlflow.log_param(\"dropout\", 0.2)\n",
    "    mlflow.log_param(\"l2\", 1e-4)\n",
    "    mlflow.log_param(\"activation_hidden\", \"ReLU\")\n",
    "\n",
    "    nn5 = build_nn5(X_train_scaled.shape[1])\n",
    "\n",
    "    history5 = nn5.fit(\n",
    "        X_train_scaled, y_train,\n",
    "        validation_split=0.2,\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        verbose=1,\n",
    "        callbacks=[\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                patience=12,\n",
    "                restore_best_weights=True\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    mae_nn5, rmse_nn5, r2_nn5 = evaluate_on_real_scale(nn5, X_test_scaled, y_test, prefix=\"NN5\")\n",
    "\n",
    "    mlflow.log_metric(\"MAE_real\", mae_nn5)\n",
    "    mlflow.log_metric(\"RMSE_real\", rmse_nn5)\n",
    "    mlflow.log_metric(\"R2_real\", r2_nn5)\n",
    "\n",
    "    mlflow.keras.log_model(nn5, artifact_path=\"nn5_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3680faa",
   "metadata": {},
   "source": [
    "Modelo NN6 – Red grande con dropout fuerte\n",
    "En este modelo uso una arquitectura grande (256, 256, 128, 64) con dropout alto (0.5, 0.5 y 0.3) para controlar sobreajuste.  \n",
    "El learning rate es bajo (0.0003) para hacer el entrenamiento más estable.  \n",
    "El objetivo es evaluar si una red de alta capacidad mejora el desempeño al comparar con los modelos anteriores.  \n",
    "Todo el entrenamiento queda registrado en MLflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6e79ba31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/01 15:16:16 WARNING mlflow.keras.autologging: Failed to log dataset information to MLflow. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - loss: 27.0783 - mae: 4.6435 - val_loss: 16.5253 - val_mae: 3.9772 - learning_rate: 3.0000e-04\n",
      "Epoch 2/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 24.6869 - mae: 3.9700 - val_loss: 13.7711 - val_mae: 3.1682 - learning_rate: 3.0000e-04\n",
      "Epoch 3/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 107.1667 - mae: 7.0019 - val_loss: 16.6336 - val_mae: 3.7418 - learning_rate: 3.0000e-04\n",
      "Epoch 4/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 221.4662 - mae: 10.2091 - val_loss: 345.3941 - val_mae: 14.6128 - learning_rate: 3.0000e-04\n",
      "Epoch 5/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 396.8261 - mae: 12.5767 - val_loss: 2233.7998 - val_mae: 37.7726 - learning_rate: 3.0000e-04\n",
      "Epoch 6/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 946.8986 - mae: 18.6614 - val_loss: 138.2809 - val_mae: 9.5712 - learning_rate: 3.0000e-04\n",
      "Epoch 7/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 475.0787 - mae: 11.8138 - val_loss: 687.4249 - val_mae: 21.1756 - learning_rate: 3.0000e-04\n",
      "Epoch 8/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 2248.1934 - mae: 30.8321 - val_loss: 52.8156 - val_mae: 5.6876 - learning_rate: 3.0000e-04\n",
      "Epoch 9/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 1086.0327 - mae: 21.1887 - val_loss: 15.9862 - val_mae: 3.5545 - learning_rate: 3.0000e-04\n",
      "Epoch 10/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 81.9276 - mae: 6.2632 - val_loss: 12.5173 - val_mae: 3.4033 - learning_rate: 1.5000e-04\n",
      "Epoch 11/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 20.9879 - mae: 3.8157 - val_loss: 11.8459 - val_mae: 3.3595 - learning_rate: 1.5000e-04\n",
      "Epoch 12/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 19.0613 - mae: 3.6764 - val_loss: 16.3758 - val_mae: 3.4894 - learning_rate: 1.5000e-04\n",
      "Epoch 13/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 20.5529 - mae: 3.7709 - val_loss: 33.1626 - val_mae: 4.5710 - learning_rate: 1.5000e-04\n",
      "Epoch 14/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 597.9403 - mae: 14.5752 - val_loss: 625.5418 - val_mae: 20.0619 - learning_rate: 1.5000e-04\n",
      "Epoch 15/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 1186.6079 - mae: 22.1993 - val_loss: 52.4876 - val_mae: 5.7048 - learning_rate: 1.5000e-04\n",
      "Epoch 16/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 759.1471 - mae: 17.4804 - val_loss: 409.8769 - val_mae: 16.2080 - learning_rate: 1.5000e-04\n",
      "Epoch 17/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 301.6867 - mae: 10.9594 - val_loss: 11.2664 - val_mae: 3.0745 - learning_rate: 1.5000e-04\n",
      "Epoch 18/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 27.4936 - mae: 4.0118 - val_loss: 22.3362 - val_mae: 3.7715 - learning_rate: 1.5000e-04\n",
      "Epoch 19/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 1885.7953 - mae: 20.4218 - val_loss: 983.7497 - val_mae: 25.1294 - learning_rate: 1.5000e-04\n",
      "Epoch 20/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 3190.7815 - mae: 32.9172 - val_loss: 34.4361 - val_mae: 4.6545 - learning_rate: 1.5000e-04\n",
      "Epoch 21/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 107.7084 - mae: 6.7682 - val_loss: 24.8122 - val_mae: 3.9569 - learning_rate: 1.5000e-04\n",
      "Epoch 22/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 88.5741 - mae: 6.4382 - val_loss: 10.0471 - val_mae: 2.8767 - learning_rate: 1.5000e-04\n",
      "Epoch 23/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 24.4477 - mae: 3.8399 - val_loss: 70.2613 - val_mae: 6.6831 - learning_rate: 1.5000e-04\n",
      "Epoch 24/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 33.4238 - mae: 4.2605 - val_loss: 19.9605 - val_mae: 3.5913 - learning_rate: 1.5000e-04\n",
      "Epoch 25/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 20.0271 - mae: 3.5086 - val_loss: 9.1549 - val_mae: 2.7394 - learning_rate: 1.5000e-04\n",
      "Epoch 26/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 2287.5142 - mae: 28.4998 - val_loss: 317.4445 - val_mae: 14.1738 - learning_rate: 1.5000e-04\n",
      "Epoch 27/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7164.8013 - mae: 53.1247 - val_loss: 10816.6064 - val_mae: 82.8786 - learning_rate: 1.5000e-04\n",
      "Epoch 28/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 6532.8232 - mae: 48.7181 - val_loss: 38.4221 - val_mae: 4.8779 - learning_rate: 1.5000e-04\n",
      "Epoch 29/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 1064.3420 - mae: 19.5611 - val_loss: 330.2796 - val_mae: 14.4309 - learning_rate: 1.5000e-04\n",
      "Epoch 30/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 197.6165 - mae: 9.0110 - val_loss: 12.5398 - val_mae: 2.8510 - learning_rate: 1.5000e-04\n",
      "Epoch 31/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 27.9569 - mae: 3.8209 - val_loss: 29.4146 - val_mae: 4.2847 - learning_rate: 1.5000e-04\n",
      "Epoch 32/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 22.0055 - mae: 3.5463 - val_loss: 9.2957 - val_mae: 2.5410 - learning_rate: 1.5000e-04\n",
      "Epoch 33/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.1644 - mae: 2.6009 - val_loss: 9.8119 - val_mae: 2.5705 - learning_rate: 7.5000e-05\n",
      "Epoch 34/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.3217 - mae: 2.5363 - val_loss: 6.5558 - val_mae: 2.4674 - learning_rate: 7.5000e-05\n",
      "Epoch 35/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.4882 - mae: 2.5260 - val_loss: 7.3554 - val_mae: 2.4410 - learning_rate: 7.5000e-05\n",
      "Epoch 36/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 12.1526 - mae: 2.8457 - val_loss: 16.4329 - val_mae: 3.2025 - learning_rate: 7.5000e-05\n",
      "Epoch 37/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 10.3415 - mae: 2.6902 - val_loss: 17.2833 - val_mae: 3.3270 - learning_rate: 7.5000e-05\n",
      "Epoch 38/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 11.7972 - mae: 2.7958 - val_loss: 9.5422 - val_mae: 2.6170 - learning_rate: 7.5000e-05\n",
      "Epoch 39/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 10.1609 - mae: 2.6555 - val_loss: 7.2046 - val_mae: 2.4159 - learning_rate: 7.5000e-05\n",
      "Epoch 40/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 11.1874 - mae: 2.6804 - val_loss: 383.2488 - val_mae: 15.5505 - learning_rate: 7.5000e-05\n",
      "Epoch 41/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 222.6523 - mae: 9.1942 - val_loss: 243.5474 - val_mae: 12.4323 - learning_rate: 7.5000e-05\n",
      "Epoch 42/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 46.0363 - mae: 4.4525 - val_loss: 29.2865 - val_mae: 4.2722 - learning_rate: 3.7500e-05\n",
      "Epoch 43/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 14.8648 - mae: 2.9950 - val_loss: 5.9510 - val_mae: 2.3295 - learning_rate: 3.7500e-05\n",
      "Epoch 44/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.0461 - mae: 2.5252 - val_loss: 9.7572 - val_mae: 2.5126 - learning_rate: 3.7500e-05\n",
      "Epoch 45/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.6497 - mae: 2.4189 - val_loss: 5.7727 - val_mae: 2.2976 - learning_rate: 3.7500e-05\n",
      "Epoch 46/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.0556 - mae: 2.3444 - val_loss: 6.0100 - val_mae: 2.2787 - learning_rate: 3.7500e-05\n",
      "Epoch 47/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 10.0334 - mae: 2.5748 - val_loss: 16.6142 - val_mae: 3.2069 - learning_rate: 3.7500e-05\n",
      "Epoch 48/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 12.2616 - mae: 2.7930 - val_loss: 14.0052 - val_mae: 3.0089 - learning_rate: 3.7500e-05\n",
      "Epoch 49/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 100.4677 - mae: 6.5442 - val_loss: 5.4931 - val_mae: 2.2450 - learning_rate: 3.7500e-05\n",
      "Epoch 50/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 16.5330 - mae: 3.0128 - val_loss: 7.4272 - val_mae: 2.3513 - learning_rate: 3.7500e-05\n",
      "Epoch 51/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 16.4828 - mae: 3.0808 - val_loss: 23.5266 - val_mae: 3.8357 - learning_rate: 3.7500e-05\n",
      "Epoch 52/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 47.1201 - mae: 4.6628 - val_loss: 324.2099 - val_mae: 14.3360 - learning_rate: 3.7500e-05\n",
      "Epoch 53/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 183.2751 - mae: 9.2647 - val_loss: 112.8364 - val_mae: 8.4139 - learning_rate: 3.7500e-05\n",
      "Epoch 54/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 216.4044 - mae: 9.3859 - val_loss: 67.0138 - val_mae: 6.4659 - learning_rate: 3.7500e-05\n",
      "Epoch 55/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 73.4752 - mae: 5.7566 - val_loss: 15.3500 - val_mae: 3.1213 - learning_rate: 3.7500e-05\n",
      "Epoch 56/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 95.2469 - mae: 6.4960 - val_loss: 64.5334 - val_mae: 6.3656 - learning_rate: 3.7500e-05\n",
      "Epoch 57/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 27.0289 - mae: 3.5719 - val_loss: 15.4353 - val_mae: 3.0848 - learning_rate: 1.8750e-05\n",
      "Epoch 58/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 12.6201 - mae: 2.7618 - val_loss: 5.4784 - val_mae: 2.1163 - learning_rate: 1.8750e-05\n",
      "Epoch 59/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.4968 - mae: 2.2992 - val_loss: 9.0239 - val_mae: 2.3890 - learning_rate: 1.8750e-05\n",
      "Epoch 60/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 6.1277 - mae: 2.1874 - val_loss: 7.5279 - val_mae: 2.3160 - learning_rate: 1.8750e-05\n",
      "Epoch 61/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.6415 - mae: 2.4781 - val_loss: 71.4746 - val_mae: 6.6822 - learning_rate: 1.8750e-05\n",
      "Epoch 62/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 23.3412 - mae: 3.4486 - val_loss: 82.8617 - val_mae: 7.2026 - learning_rate: 1.8750e-05\n",
      "Epoch 63/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 57.9040 - mae: 5.0639 - val_loss: 7.6852 - val_mae: 2.3229 - learning_rate: 1.8750e-05\n",
      "Epoch 64/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 12.0118 - mae: 2.6629 - val_loss: 6.2395 - val_mae: 2.1645 - learning_rate: 1.8750e-05\n",
      "Epoch 65/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.2790 - mae: 2.4378 - val_loss: 5.9414 - val_mae: 2.1299 - learning_rate: 1.8750e-05\n",
      "Epoch 66/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 6.4421 - mae: 2.1771 - val_loss: 4.7458 - val_mae: 2.0610 - learning_rate: 9.3750e-06\n",
      "Epoch 67/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 5.6131 - mae: 2.1081 - val_loss: 5.3564 - val_mae: 2.0781 - learning_rate: 9.3750e-06\n",
      "Epoch 68/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 5.8937 - mae: 2.1141 - val_loss: 6.0690 - val_mae: 2.1349 - learning_rate: 9.3750e-06\n",
      "Epoch 69/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 5.7703 - mae: 2.0960 - val_loss: 4.9085 - val_mae: 2.0292 - learning_rate: 9.3750e-06\n",
      "Epoch 70/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 6.1921 - mae: 2.1406 - val_loss: 7.9007 - val_mae: 2.3356 - learning_rate: 9.3750e-06\n",
      "Epoch 71/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.1241 - mae: 2.2060 - val_loss: 6.6560 - val_mae: 2.1018 - learning_rate: 9.3750e-06\n",
      "Epoch 72/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 5.9657 - mae: 2.0930 - val_loss: 4.9180 - val_mae: 2.0116 - learning_rate: 9.3750e-06\n",
      "Epoch 73/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.4049 - mae: 2.4125 - val_loss: 17.5513 - val_mae: 3.2794 - learning_rate: 9.3750e-06\n",
      "Epoch 74/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.2995 - mae: 2.2302 - val_loss: 4.7330 - val_mae: 2.0214 - learning_rate: 4.6875e-06\n",
      "Epoch 75/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 5.6858 - mae: 2.0814 - val_loss: 4.9824 - val_mae: 2.0273 - learning_rate: 4.6875e-06\n",
      "Epoch 76/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 5.1492 - mae: 2.0349 - val_loss: 5.7057 - val_mae: 2.0809 - learning_rate: 4.6875e-06\n",
      "Epoch 77/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 5.0726 - mae: 2.0124 - val_loss: 4.5450 - val_mae: 1.9959 - learning_rate: 4.6875e-06\n",
      "Epoch 78/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 5.3496 - mae: 2.0510 - val_loss: 4.6746 - val_mae: 2.0087 - learning_rate: 4.6875e-06\n",
      "Epoch 79/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 5.5851 - mae: 2.0663 - val_loss: 4.6405 - val_mae: 1.9868 - learning_rate: 4.6875e-06\n",
      "Epoch 80/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 5.6037 - mae: 2.0584 - val_loss: 7.1208 - val_mae: 2.2349 - learning_rate: 4.6875e-06\n",
      "Epoch 81/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 10.5351 - mae: 2.5201 - val_loss: 4.4359 - val_mae: 1.9878 - learning_rate: 4.6875e-06\n",
      "Epoch 82/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 5.9788 - mae: 2.0923 - val_loss: 4.3833 - val_mae: 1.9814 - learning_rate: 4.6875e-06\n",
      "Epoch 83/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 8.0467 - mae: 2.2610 - val_loss: 4.4342 - val_mae: 1.9743 - learning_rate: 4.6875e-06\n",
      "Epoch 84/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 13.0104 - mae: 2.6434 - val_loss: 14.7346 - val_mae: 3.0537 - learning_rate: 4.6875e-06\n",
      "Epoch 85/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.9050 - mae: 2.2783 - val_loss: 4.5449 - val_mae: 1.9793 - learning_rate: 4.6875e-06\n",
      "Epoch 86/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 14.1675 - mae: 2.8070 - val_loss: 5.9604 - val_mae: 2.0120 - learning_rate: 4.6875e-06\n",
      "Epoch 87/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.4582 - mae: 2.3935 - val_loss: 18.3769 - val_mae: 3.3961 - learning_rate: 4.6875e-06\n",
      "Epoch 88/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.0238 - mae: 2.1911 - val_loss: 7.6066 - val_mae: 2.2820 - learning_rate: 4.6875e-06\n",
      "Epoch 89/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 7.9348 - mae: 2.2995 - val_loss: 7.3632 - val_mae: 2.2536 - learning_rate: 4.6875e-06\n",
      "Epoch 90/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 4.9371 - mae: 1.9743 - val_loss: 6.2256 - val_mae: 2.0292 - learning_rate: 2.3438e-06\n",
      "Epoch 91/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.6331 - mae: 1.9332 - val_loss: 4.4328 - val_mae: 1.9598 - learning_rate: 2.3438e-06\n",
      "Epoch 92/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.5918 - mae: 1.9395 - val_loss: 6.1795 - val_mae: 2.0227 - learning_rate: 2.3438e-06\n",
      "Epoch 93/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 5.0498 - mae: 1.9801 - val_loss: 4.2897 - val_mae: 1.9497 - learning_rate: 2.3438e-06\n",
      "Epoch 94/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 4.7867 - mae: 1.9600 - val_loss: 4.2386 - val_mae: 1.9462 - learning_rate: 2.3438e-06\n",
      "Epoch 95/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 5.0672 - mae: 1.9868 - val_loss: 4.5303 - val_mae: 1.9555 - learning_rate: 2.3438e-06\n",
      "Epoch 96/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 5.7339 - mae: 2.0357 - val_loss: 9.7832 - val_mae: 2.5274 - learning_rate: 2.3438e-06\n",
      "Epoch 97/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 6.7304 - mae: 2.1417 - val_loss: 4.5808 - val_mae: 1.9534 - learning_rate: 2.3438e-06\n",
      "Epoch 98/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 4.9298 - mae: 1.9634 - val_loss: 4.1977 - val_mae: 1.9351 - learning_rate: 2.3438e-06\n",
      "Epoch 99/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 5.0018 - mae: 1.9776 - val_loss: 4.2077 - val_mae: 1.9370 - learning_rate: 2.3438e-06\n",
      "Epoch 100/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 5.0559 - mae: 1.9726 - val_loss: 4.2277 - val_mae: 1.9280 - learning_rate: 2.3438e-06\n",
      "Epoch 101/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 5.1128 - mae: 1.9691 - val_loss: 4.9204 - val_mae: 1.9268 - learning_rate: 2.3438e-06\n",
      "Epoch 102/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 4.6644 - mae: 1.9447 - val_loss: 7.5269 - val_mae: 2.2661 - learning_rate: 2.3438e-06\n",
      "Epoch 103/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 5.9948 - mae: 2.0604 - val_loss: 4.1790 - val_mae: 1.9267 - learning_rate: 2.3438e-06\n",
      "Epoch 104/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 7.2055 - mae: 2.1822 - val_loss: 8.3273 - val_mae: 2.3592 - learning_rate: 2.3438e-06\n",
      "Epoch 105/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 5.5866 - mae: 2.0145 - val_loss: 15.0884 - val_mae: 3.0349 - learning_rate: 2.3438e-06\n",
      "Epoch 106/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.0840 - mae: 2.0854 - val_loss: 4.3017 - val_mae: 1.9093 - learning_rate: 2.3438e-06\n",
      "Epoch 107/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.7356 - mae: 1.9369 - val_loss: 4.8668 - val_mae: 1.9128 - learning_rate: 2.3438e-06\n",
      "Epoch 108/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 5.9738 - mae: 2.0672 - val_loss: 4.2580 - val_mae: 1.9219 - learning_rate: 2.3438e-06\n",
      "Epoch 109/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 5.6827 - mae: 2.0215 - val_loss: 10.3460 - val_mae: 2.5864 - learning_rate: 2.3438e-06\n",
      "Epoch 110/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 5.8020 - mae: 2.0459 - val_loss: 4.9251 - val_mae: 1.9553 - learning_rate: 2.3438e-06\n",
      "Epoch 111/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 4.4272 - mae: 1.8913 - val_loss: 4.2269 - val_mae: 1.9158 - learning_rate: 1.1719e-06\n",
      "Epoch 112/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 4.2964 - mae: 1.8902 - val_loss: 4.9768 - val_mae: 1.9586 - learning_rate: 1.1719e-06\n",
      "Epoch 113/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.3451 - mae: 1.8946 - val_loss: 4.1564 - val_mae: 1.8991 - learning_rate: 1.1719e-06\n",
      "Epoch 114/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 4.2941 - mae: 1.8794 - val_loss: 4.6474 - val_mae: 1.9308 - learning_rate: 1.1719e-06\n",
      "Epoch 115/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 5.4044 - mae: 1.9954 - val_loss: 4.2295 - val_mae: 1.8952 - learning_rate: 1.1719e-06\n",
      "Epoch 116/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.6475 - mae: 1.9273 - val_loss: 4.3300 - val_mae: 1.8914 - learning_rate: 1.1719e-06\n",
      "Epoch 117/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 4.7292 - mae: 1.9264 - val_loss: 5.0667 - val_mae: 1.9101 - learning_rate: 1.1719e-06\n",
      "Epoch 118/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.7662 - mae: 1.9342 - val_loss: 5.7929 - val_mae: 2.0481 - learning_rate: 1.1719e-06\n",
      "Epoch 119/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.4048 - mae: 1.8940 - val_loss: 5.1732 - val_mae: 1.9123 - learning_rate: 1.1719e-06\n",
      "Epoch 120/120\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.6365 - mae: 1.9050 - val_loss: 4.0788 - val_mae: 1.8997 - learning_rate: 1.1719e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/01 15:19:35 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/01 15:19:43 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN6 - MAE: 220.92, RMSE: 422.69, R2: -0.3135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/01 15:19:43 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "\u001b[31m2025/12/01 15:19:49 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def build_nn6(n_features: int):\n",
    "    inp = keras.Input(shape=(n_features,))\n",
    "\n",
    "    x = layers.Dense(256, activation=\"relu\")(inp)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    x = layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    x = layers.Dense(128, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    x = layers.Dense(64, activation=\"relu\")(x)\n",
    "    out = layers.Dense(1)(x)\n",
    "\n",
    "    model = keras.Model(inputs=inp, outputs=out)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=3e-4),\n",
    "        loss=\"mse\",\n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "mae_nn6 = rmse_nn6 = r2_nn6 = None\n",
    "\n",
    "with mlflow.start_run(run_name=\"NN6_big_dropout_lowLR\"):\n",
    "    mlflow.log_param(\"model_type\", \"NN6_big_dropout_lowLR\")\n",
    "    mlflow.log_param(\"layers\", \"256 -> 256 -> 128 -> 64 -> 1\")\n",
    "    mlflow.log_param(\"learning_rate\", 3e-4)\n",
    "    mlflow.log_param(\"dropout\", \"0.5, 0.5, 0.3\")\n",
    "    mlflow.log_param(\"activation_hidden\", \"ReLU\")\n",
    "\n",
    "    nn6 = build_nn6(X_train_scaled.shape[1])\n",
    "\n",
    "    history6 = nn6.fit(\n",
    "        X_train_scaled, y_train,\n",
    "        validation_split=0.2,\n",
    "        epochs=120,\n",
    "        batch_size=32,\n",
    "        verbose=1,\n",
    "        callbacks=[\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                patience=15,\n",
    "                restore_best_weights=True\n",
    "            ),\n",
    "            keras.callbacks.ReduceLROnPlateau(\n",
    "                patience=7,\n",
    "                factor=0.5\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    mae_nn6, rmse_nn6, r2_nn6 = evaluate_on_real_scale(nn6, X_test_scaled, y_test, prefix=\"NN6\")\n",
    "\n",
    "    mlflow.log_metric(\"MAE_real\", mae_nn6)\n",
    "    mlflow.log_metric(\"RMSE_real\", rmse_nn6)\n",
    "    mlflow.log_metric(\"R2_real\", r2_nn6)\n",
    "\n",
    "    mlflow.keras.log_model(nn6, artifact_path=\"nn6_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "929be8ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NN1_baseline</td>\n",
       "      <td>110.792830</td>\n",
       "      <td>339.576092</td>\n",
       "      <td>0.152282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NN2_deeper_dropout</td>\n",
       "      <td>605.196646</td>\n",
       "      <td>10258.411950</td>\n",
       "      <td>-772.637290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NN3_deep_bn_dropout</td>\n",
       "      <td>98.876599</td>\n",
       "      <td>318.992990</td>\n",
       "      <td>0.251935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NNJD_128_bn_dropout</td>\n",
       "      <td>99.472153</td>\n",
       "      <td>320.653136</td>\n",
       "      <td>0.089150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NN4_low_lr_bs64</td>\n",
       "      <td>117.498517</td>\n",
       "      <td>351.993625</td>\n",
       "      <td>0.244128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NN5_l2_dropout_arch256</td>\n",
       "      <td>222.087464</td>\n",
       "      <td>2095.753154</td>\n",
       "      <td>-31.289207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NN6_big_dropout_lowLR</td>\n",
       "      <td>220.924395</td>\n",
       "      <td>422.694190</td>\n",
       "      <td>-0.313499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model         MAE          RMSE          R2\n",
       "0            NN1_baseline  110.792830    339.576092    0.152282\n",
       "1      NN2_deeper_dropout  605.196646  10258.411950 -772.637290\n",
       "2     NN3_deep_bn_dropout   98.876599    318.992990    0.251935\n",
       "3     NNJD_128_bn_dropout   99.472153    320.653136    0.089150\n",
       "4         NN4_low_lr_bs64  117.498517    351.993625    0.244128\n",
       "5  NN5_l2_dropout_arch256  222.087464   2095.753154  -31.289207\n",
       "6   NN6_big_dropout_lowLR  220.924395    422.694190   -0.313499"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_nn_full = pd.DataFrame({\n",
    "    \"Model\": [\n",
    "        \"NN1_baseline\",\n",
    "        \"NN2_deeper_dropout\",\n",
    "        \"NN3_deep_bn_dropout\",\n",
    "        \"NNJD_128_bn_dropout\",\n",
    "        \"NN4_low_lr_bs64\",\n",
    "        \"NN5_l2_dropout_arch256\",\n",
    "        \"NN6_big_dropout_lowLR\"\n",
    "    ],\n",
    "    \"MAE\": [mae_nn1, mae_nn2, mae_nn3, mae_nnJD, mae_nn4, mae_nn5, mae_nn6],\n",
    "    \"RMSE\": [rmse_nn1, rmse_nn2, rmse_nn3, rmse_nnJD, rmse_nn4, rmse_nn5, rmse_nn6],\n",
    "    \"R2\": [r2_nn1, r2_nn2, r2_nn3, r2_nn4, r2_nnJD, r2_nn5, r2_nn6]\n",
    "})\n",
    "\n",
    "results_nn_full"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
